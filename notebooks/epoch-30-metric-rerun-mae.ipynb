{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep and modeling\n",
    "\n",
    "The first half of this notebook is basically converting the dictionary of dataframes built in the timeline notebook into train, val, and test sets consisting of tensors of timeframes as their features and tensors of positions as their targets.\n",
    "\n",
    "The second half is building models (and a custon loss function) and then evaluating them.\n",
    "\n",
    "Some of the tools here are based on the tensorflow guide on time series - though they were heavily modified.\n",
    "https://www.tensorflow.org/tutorials/structured_data/time_series/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "\n",
    "# these are from the keras guide\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparing the data a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the game-dataframe dictionary\n",
    "dfs_dict = pickle.load(open(\"../data/timeline-di.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I split the dataframe by game. If using the model to predict future clid games, the ids shouldn't be shuffled.\n",
    "gameids = list(dfs_dict.keys())\n",
    "np.random.shuffle(gameids)\n",
    "idcount = len(gameids)\n",
    "# these can be changed if different sized splits are wanted\n",
    "# (or remove older games if ids are sorted)\n",
    "splits = [int(idcount*i) for i in [0,.8,.9,1]]\n",
    "train_ids = gameids[splits[0]:splits[1]]\n",
    "val_ids = gameids[splits[1]:splits[2]]\n",
    "test_ids = gameids[splits[2]:splits[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enemy6currentGold</th>\n",
       "      <th>enemy6totalGold</th>\n",
       "      <th>enemy6level</th>\n",
       "      <th>enemy6jungleMinionsKilled</th>\n",
       "      <th>enemy6x</th>\n",
       "      <th>enemy6y</th>\n",
       "      <th>enemy7currentGold</th>\n",
       "      <th>enemy7totalGold</th>\n",
       "      <th>enemy7level</th>\n",
       "      <th>enemy7jungleMinionsKilled</th>\n",
       "      <th>...</th>\n",
       "      <th>ally4jungleMinionsKilled</th>\n",
       "      <th>ally4x</th>\n",
       "      <th>ally4y</th>\n",
       "      <th>ally_side</th>\n",
       "      <th>playercurrentGold</th>\n",
       "      <th>playertotalGold</th>\n",
       "      <th>playerlevel</th>\n",
       "      <th>playerjungleMinionsKilled</th>\n",
       "      <th>playerx</th>\n",
       "      <th>playery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14237.0</td>\n",
       "      <td>14579.0</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14486</td>\n",
       "      <td>14291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6882.0</td>\n",
       "      <td>6193.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8509.0</td>\n",
       "      <td>5793.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6898</td>\n",
       "      <td>8118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6210.0</td>\n",
       "      <td>6515.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13097.0</td>\n",
       "      <td>2406.0</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>620</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11453</td>\n",
       "      <td>6775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>678.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8081.0</td>\n",
       "      <td>6800.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14340.0</td>\n",
       "      <td>14391.0</td>\n",
       "      <td>1</td>\n",
       "      <td>579</td>\n",
       "      <td>1079</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>12431</td>\n",
       "      <td>2627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.0</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5373.0</td>\n",
       "      <td>5570.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>1162.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13769.0</td>\n",
       "      <td>4030.0</td>\n",
       "      <td>1</td>\n",
       "      <td>758</td>\n",
       "      <td>1258</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>10996</td>\n",
       "      <td>8668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>411.0</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7192.0</td>\n",
       "      <td>7922.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13341.0</td>\n",
       "      <td>2434.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1152</td>\n",
       "      <td>1652</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>6601</td>\n",
       "      <td>12746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60.0</td>\n",
       "      <td>2095.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2838.0</td>\n",
       "      <td>2296.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12671.0</td>\n",
       "      <td>2094.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1962</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>13522</td>\n",
       "      <td>7877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>301.0</td>\n",
       "      <td>2336.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6808.0</td>\n",
       "      <td>7439.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>2259.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12705.0</td>\n",
       "      <td>3059.0</td>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>2205</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>11064</td>\n",
       "      <td>8619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>625.0</td>\n",
       "      <td>2660.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8198.0</td>\n",
       "      <td>6693.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>2549.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12988.0</td>\n",
       "      <td>3607.0</td>\n",
       "      <td>1</td>\n",
       "      <td>657</td>\n",
       "      <td>2582</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>7533</td>\n",
       "      <td>8352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>218.0</td>\n",
       "      <td>2953.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6421.0</td>\n",
       "      <td>6660.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>2877.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12922.0</td>\n",
       "      <td>2098.0</td>\n",
       "      <td>1</td>\n",
       "      <td>801</td>\n",
       "      <td>2726</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>12571</td>\n",
       "      <td>6306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   enemy6currentGold  enemy6totalGold  enemy6level  enemy6jungleMinionsKilled  \\\n",
       "0              500.0            500.0          1.0                        0.0   \n",
       "1                0.0            500.0          1.0                        0.0   \n",
       "2               83.0            583.0          1.0                        0.0   \n",
       "3              678.0           1178.0          3.0                        0.0   \n",
       "4               79.0           1364.0          3.0                        0.0   \n",
       "5              411.0           1696.0          5.0                        0.0   \n",
       "6               60.0           2095.0          5.0                        0.0   \n",
       "7              301.0           2336.0          6.0                        0.0   \n",
       "8              625.0           2660.0          7.0                        0.0   \n",
       "9              218.0           2953.0          7.0                        0.0   \n",
       "\n",
       "   enemy6x  enemy6y  enemy7currentGold  enemy7totalGold  enemy7level  \\\n",
       "0    351.0    293.0              500.0            500.0          1.0   \n",
       "1   6882.0   6193.0                0.0            500.0          1.0   \n",
       "2   6210.0   6515.0               97.0            597.0          1.0   \n",
       "3   8081.0   6800.0              427.0            927.0          3.0   \n",
       "4   5373.0   5570.0              662.0           1162.0          4.0   \n",
       "5   7192.0   7922.0               50.0           1550.0          5.0   \n",
       "6   2838.0   2296.0              114.0           1764.0          5.0   \n",
       "7   6808.0   7439.0              609.0           2259.0          6.0   \n",
       "8   8198.0   6693.0              899.0           2549.0          7.0   \n",
       "9   6421.0   6660.0              427.0           2877.0          7.0   \n",
       "\n",
       "   enemy7jungleMinionsKilled  ...  ally4jungleMinionsKilled   ally4x   ally4y  \\\n",
       "0                        0.0  ...                       0.0  14237.0  14579.0   \n",
       "1                        0.0  ...                       0.0   8509.0   5793.0   \n",
       "2                        0.0  ...                       0.0  13097.0   2406.0   \n",
       "3                        0.0  ...                       0.0  14340.0  14391.0   \n",
       "4                        0.0  ...                       0.0  13769.0   4030.0   \n",
       "5                        0.0  ...                       0.0  13341.0   2434.0   \n",
       "6                        0.0  ...                       0.0  12671.0   2094.0   \n",
       "7                        4.0  ...                       0.0  12705.0   3059.0   \n",
       "8                        4.0  ...                       0.0  12988.0   3607.0   \n",
       "9                        4.0  ...                       0.0  12922.0   2098.0   \n",
       "\n",
       "   ally_side  playercurrentGold  playertotalGold  playerlevel  \\\n",
       "0          1                500              500            1   \n",
       "1          1                  0              500            1   \n",
       "2          1                120              620            2   \n",
       "3          1                579             1079            3   \n",
       "4          1                758             1258            3   \n",
       "5          1               1152             1652            4   \n",
       "6          1                 37             1962            4   \n",
       "7          1                280             2205            5   \n",
       "8          1                657             2582            6   \n",
       "9          1                801             2726            6   \n",
       "\n",
       "   playerjungleMinionsKilled  playerx  playery  \n",
       "0                          0    14486    14291  \n",
       "1                          0     6898     8118  \n",
       "2                          4    11453     6775  \n",
       "3                         12    12431     2627  \n",
       "4                         13    10996     8668  \n",
       "5                         23     6601    12746  \n",
       "6                         24    13522     7877  \n",
       "7                         29    11064     8619  \n",
       "8                         40     7533     8352  \n",
       "9                         40    12571     6306  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking things are working\n",
    "dfs_dict[train_ids[1]][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cases that aren't used much anymore\n",
    "test0 = dfs_dict[train_ids[0]][0:20]\n",
    "test1 = dfs_dict[train_ids[1]][0:20]\n",
    "column_indices = {name: i for i, name in enumerate(test0.columns)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting to make classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "    \"\"\"\n",
    "    This class is heavily based on the tensorflow guide. It allows you\n",
    "    to create windows from a dataset. Currently a different one needs\n",
    "    to be called for each window shape, which isn't ideal but is \n",
    "    complicated to improve.\n",
    "    \n",
    "        Arguments:\n",
    "    input_width: int of how many time steps back the feature set should\n",
    "                 include.\n",
    "                 \n",
    "    label_width: int of how many time steps the label set should\n",
    "                 include. This is always 1 for windows meant for models,\n",
    "                 but windows made for plotting have larger values.\n",
    "                 \n",
    "    shift:       Always should be 1 as far as I can tell, indicates\n",
    "                 how far into the future to predict. \n",
    "                 \n",
    "    eg_df:       Basically just used to get column names but ideally\n",
    "                 should be removed.\n",
    "    \n",
    "    dfdi:        Dictionary of game dataframes, with gameids as index\n",
    "    \n",
    "    label_columns: List of the columns of the dfs which are the target.\n",
    "    \n",
    "    train_ids, val_ids, and test_ids: Lists of game ids determined earlier.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "                 eg_df=test0, val_df = test1,\n",
    "                 dfdi=dfs_dict,\n",
    "                 train_ids=train_ids,\n",
    "                 val_ids=val_ids,\n",
    "                 test_ids=test_ids,\n",
    "                 label_columns=None):\n",
    "        \n",
    "        # Store the dfs etc in the class.\n",
    "        self.eg_df = eg_df\n",
    "        self.val_df = val_df\n",
    "        self.dfdi = dfdi\n",
    "        \n",
    "        self.train_ids = train_ids\n",
    "        self.val_ids = val_ids\n",
    "        self.test_ids = test_ids\n",
    "        \n",
    "        self.trainli = None\n",
    "        self.valli = None\n",
    "        self.testli = None\n",
    "\n",
    "        # Work out the label column indices.\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in enumerate(eg_df.columns)}\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "                f'Total window size: {self.total_window_size}',\n",
    "                f'Input indices: {self.input_indices}',\n",
    "                f'Label indices: {self.label_indices}',\n",
    "                f'Label column name(s): {self.label_columns}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_window(self, features):\n",
    "    \"\"\"\n",
    "    Splits window into labels and features.\n",
    "    \n",
    "    features: The full data being split. (tensor format I think)\n",
    "    \n",
    "    \"\"\"\n",
    "    inputs = features[:, self.input_slice, :]\n",
    "    labels = features[:, self.labels_slice, :]\n",
    "    if self.label_columns is not None:\n",
    "        # Stacking the two labels because there's x and y!\n",
    "        labels = tf.stack(\n",
    "                [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1)\n",
    "    \n",
    "    \n",
    "    # Guide says this, not exactly sure what setting the shapes does exactly:\n",
    "    # Slicing doesn't preserve static shape information, so set the shapes\n",
    "    # manually. This way the 'tf.data.Datasets' are easier to inspect.\n",
    "    inputs.set_shape([None, self.input_width, None])\n",
    "    labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "WindowGenerator.split_window = split_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map2(self, model=None, input_width=3, plot_col=[\"playerx\",\"playery\"], max_subplots=3):\n",
    "    \"\"\"\n",
    "    Plots predictions of 3 random windows from the val set of a given model.\n",
    "    Based very very vaguely on the tensorflow guide.\n",
    "    \n",
    "        Arguments:\n",
    "    model: the model (tf objects only, probably).\n",
    "    \n",
    "    input_width: how many time steps the model predicts based on.\n",
    "    \n",
    "    plot_col: list of the two columns to predict, probably always the same.\n",
    "    \n",
    "    max_subplots: number of windows to plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs, labels = self.val\n",
    "    # shuffle indices to get a random window, from\n",
    "    # https://stackoverflow.com/questions/56575877/shuffling-two-tensors-in-the-same-order\n",
    "    indices = tf.range(start=0, limit=tf.shape(inputs)[0], dtype=tf.int32)\n",
    "    shuffled_indices = tf.random.shuffle(indices)\n",
    "    inputs = tf.gather(inputs, shuffled_indices)\n",
    "    labels = tf.gather(labels, shuffled_indices)\n",
    "    \n",
    "    plt.figure(figsize=(5, 15))\n",
    "    # get label indices\n",
    "    plot_col_index = [self.column_indices[plot_col[0]], self.column_indices[plot_col[1]]]\n",
    "    # an easier way to grab label columns! very fashionable\n",
    "    xy_inputs = tf.gather(inputs,plot_col_index,axis=2)\n",
    "    \n",
    "    # for loop, once for each window\n",
    "    max_n = min(max_subplots, len(inputs))\n",
    "    for n in range(max_n):\n",
    "        plt.subplot(3, 1, n+1)\n",
    "        plt.xlim(0,15000)\n",
    "        plt.ylim(0,15000)\n",
    "        # plot the map background\n",
    "        img = plt.imread(\"../data/map.png\")\n",
    "        plt.imshow(img, extent=[0,15000,0,15000],)\n",
    "        \n",
    "        # plot each line of the true data as well as labeling them with time\n",
    "        for i in range(xy_inputs.shape[1]):\n",
    "            plt.plot(xy_inputs[n, i:i+2, 0], xy_inputs[n, i:i+2, 1], zorder=10, color=\"blue\")#color=(.8-i/10,1-i/8,1-i/8))\n",
    "            plt.scatter(xy_inputs[n, i, 0], xy_inputs[n, i, 1],\n",
    "                     marker='${}$'.format(str(i)), s=120, zorder=20, color=\"white\")##color=(.8-i/10,1-i/8,1-i/8))\n",
    "        \n",
    "        # vestigial if\n",
    "        if model is not None:\n",
    "            # start by predicting each window  \n",
    "            predictions = []\n",
    "            for i in range(inputs.shape[1]-1):\n",
    "                try:\n",
    "                    current = model.predict(inputs[n,i:i+input_width,:])\n",
    "                    predictions.append(current[0,:])\n",
    "                except ValueError:\n",
    "                    # an attempt to make plotmap work with multistep dense - didn't help\n",
    "                    predictions = model.predict(tf.expand_dims(inputs[n,:,:],axis=0))\n",
    "                    predictions = predictions[0,:,:]\n",
    "                \n",
    "            # plot line from each prediction to the last true value its based on\n",
    "            # and keep the time label the same as the previous plotting\n",
    "            for i in range(len(predictions)-1):\n",
    "                line_x_0 = predictions[i][0]\n",
    "                line_x_1 = predictions[i+1][0]\n",
    "                line_y_0 = predictions[i][1]\n",
    "                line_y_1 = predictions[i+1][1]\n",
    "                plt.plot([xy_inputs[n, i+input_width-1, 0],line_x_0],\n",
    "                         [xy_inputs[n, i+input_width-1, 1], line_y_0], zorder=10, color=(1,0,0))\n",
    "                plt.scatter(line_x_0, line_y_0, marker='${}$'.format(str(i+input_width)),\n",
    "                            s=120, zorder=20, color=(1,.8,.5))\n",
    "        \n",
    "        # plot the last label abusing i post for loop, very cool\n",
    "        i=i+1\n",
    "        plt.scatter(xy_inputs[n, i, 0], xy_inputs[n, i, 1],\n",
    "                         marker='${}$'.format(str(i)), s=120, zorder=20, color=\"white\")\n",
    "\n",
    "    \n",
    "WindowGenerator.plot_map2 = plot_map2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(self, data, list_me=False):\n",
    "    \"\"\"\n",
    "    make_dataset converts a single game dataframe into windows.\n",
    "        \n",
    "        Arguments:\n",
    "    data: Dataframe of a single game\n",
    "    \n",
    "    list_me: Whether to return a list of windows or a map of windows.\n",
    "    \"\"\"\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    \n",
    "    # \"Creates a dataset of sliding windows over a timeseries provided as array.\"\n",
    "    ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=True,\n",
    "            batch_size=32,)\n",
    "\n",
    "    ds = ds.map(self.split_window)\n",
    "    if list_me:\n",
    "        return list(ds)\n",
    "    return ds\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_split_from_dfdi(self,minmax=(0,20)):\n",
    "    \"\"\"\n",
    "    Combines the windows from each game generated by make_dataset.\n",
    "        Arguments:\n",
    "    minmax: Tuple of what timeframe to sample from (minutes).\n",
    "    \"\"\"\n",
    "    # minmax is start and end time of window being sampled from.\n",
    "    # splits is where the data is being split for train val test split\n",
    "    if self.dfdi is None:\n",
    "        print(\"no dfdi attached\")\n",
    "        raise KeyError(\"no dfdi attached\")\n",
    "    train_ids = self.train_ids\n",
    "    val_ids = self.val_ids\n",
    "    test_ids = self.test_ids\n",
    "    if self.trainli is None:\n",
    "        trainli = build_batch(self, self.dfdi, train_ids, minmax)\n",
    "        train_feats = tf.concat([batch[0] for batch in trainli], axis=0)\n",
    "        train_labels = tf.concat([batch[1] for batch in trainli], axis=0)\n",
    "        \n",
    "    if self.valli is None:\n",
    "        valli = build_batch(self, self.dfdi, val_ids, minmax)\n",
    "        val_feats = tf.concat([batch[0] for batch in valli], axis=0)\n",
    "        val_labels = tf.concat([batch[1] for batch in valli], axis=0)\n",
    "            \n",
    "    if self.testli is None:\n",
    "        testli = build_batch(self, self.dfdi, test_ids, minmax)\n",
    "        test_feats = tf.concat([batch[0] for batch in testli], axis=0)\n",
    "        test_labels = tf.concat([batch[1] for batch in testli], axis=0)\n",
    "            \n",
    "        \n",
    "    print(train_feats.shape, train_labels.shape)\n",
    "    self.train = (train_feats, train_labels)\n",
    "    self.val = (val_feats, val_labels)\n",
    "    self.test = (test_feats, test_labels)\n",
    "    \n",
    "\n",
    "WindowGenerator.make_split_from_dfdi = make_split_from_dfdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_batch(self, dfdi, id_li, minmax):\n",
    "    \"\"\"\n",
    "    Calls make_dataset on a specific match and adds it to list. Probably\n",
    "    doesn't make enough use of self.\n",
    "    \n",
    "        Arguments:\n",
    "    dfdi: dictionary of shape matchid: dataframe.\n",
    "    \n",
    "    id_li: list of matchids to use.\n",
    "    \n",
    "    minmax: list of start and end time of what times to build from - if game is shorter than max, just uses last time\n",
    "    returns a list of tf tensors.\n",
    "    \"\"\"\n",
    "    dataset_li = []\n",
    "    for match_id in id_li:\n",
    "        df = dfdi[match_id]\n",
    "        df = df.iloc[minmax[0]:minmax[1]]\n",
    "        dataset_li = dataset_li + make_dataset(self, data=df, list_me=True)\n",
    "    return dataset_li\n",
    "\n",
    "WindowGenerator.build_batch = build_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a bunch of windows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 2\n",
       "Input indices: [0]\n",
       "Label indices: [1]\n",
       "Label column name(s): ['playerx', 'playery']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_step_window = WindowGenerator(\n",
    "    input_width=1, label_width=1, shift=1,\n",
    "    label_columns=[\"playerx\", \"playery\"])\n",
    "single_step_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 4\n",
       "Input indices: [0 1 2]\n",
       "Label indices: [3]\n",
       "Label column name(s): ['playerx', 'playery']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_window_3 = WindowGenerator(\n",
    "    input_width=3,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "    label_columns=[\"playerx\",\"playery\"])\n",
    "\n",
    "conv_window_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 5\n",
       "Input indices: [0 1 2 3]\n",
       "Label indices: [4]\n",
       "Label column name(s): ['playerx', 'playery']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_window_4 = WindowGenerator(\n",
    "    input_width=4,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "    label_columns=[\"playerx\",\"playery\"])\n",
    "\n",
    "conv_window_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 3\n",
       "Input indices: [0 1]\n",
       "Label indices: [2]\n",
       "Label column name(s): ['playerx', 'playery']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_window_2 = WindowGenerator(\n",
    "    input_width=2,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "    label_columns=[\"playerx\",\"playery\"])\n",
    "\n",
    "conv_window_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store windows as dict to cycle through\n",
    "windows = {6:conv_window_2, 8:conv_window_3, 4:conv_window_4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 11\n",
       "Input indices: [0 1 2 3 4 5 6 7 8 9]\n",
       "Label indices: [ 1  2  3  4  5  6  7  8  9 10]\n",
       "Label column name(s): ['playerx', 'playery']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for plotting\n",
    "wide_window = WindowGenerator(\n",
    "    input_width=10, label_width=10, shift=1,\n",
    "    label_columns=[\"playerx\",\"playery\"])\n",
    "\n",
    "wide_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3040, 1, 61) (3040, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "single_step_window.make_split_from_dfdi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2880, 2, 61) (2880, 1, 2)\n",
      "(2720, 3, 61) (2720, 1, 2)\n",
      "(2560, 4, 61) (2560, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "conv_window_2.make_split_from_dfdi()\n",
    "conv_window_3.make_split_from_dfdi()\n",
    "conv_window_4.make_split_from_dfdi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 10, 61) (1600, 10, 2)\n"
     ]
    }
   ],
   "source": [
    "wide_window.make_split_from_dfdi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_distance_mae(y_true, y_pred):\n",
    "    \"\"\"takes two [n,1,2] tensors and returns the mean distance between the points\"\"\"\n",
    "    # trying to make it work with lstm but ultimately failed because I can't use\n",
    "    # sequential model for multitarget lstm.\n",
    "    if y_true.shape[1:] != y_pred.shape[1:]:\n",
    "        print(y_true)\n",
    "        print(y_true[:,:,1])\n",
    "        print(y_pred)\n",
    "        #\"\"\"\n",
    "        raise ValueError(\"passed tensors have different shape \"\n",
    "                         + str(y_true.shape) + \" \"\n",
    "                         + str(y_pred.shape) + \"\\n\"\n",
    "                         + str(y_true) + \"\\n\"\n",
    "                         + str(y_pred)\n",
    "                        )\n",
    "        \n",
    "    # simple mae calculation\n",
    "    dx2 = (y_true[:,:,0] - y_pred[:,:,0])**2\n",
    "    dy2 = (y_true[:,:,1] - y_pred[:,:,1])**2\n",
    "    dist = (dx2 + dy2)**.5\n",
    "    dist_sum = tf.math.reduce_mean(dist)\n",
    "    return dist_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_distance_rmse(y_true, y_pred):\n",
    "    \"\"\"takes two [n,1,2] tensors and returns the root mean squared distance between the points\"\"\"\n",
    "    if y_true.shape[1:] != y_pred.shape[1:]:\n",
    "        raise ValueError(\"passed tensors have different shape\")\n",
    "    dx2 = (y_true[:,:,0] - y_pred[:,:,0])**2\n",
    "    dy2 = (y_true[:,:,1] - y_pred[:,:,1])**2\n",
    "    dist2 = dx2 + dy2\n",
    "    dist2_sum = tf.math.reduce_mean(dist2)\n",
    "    rmse = dist2_sum**.5\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_distance_log_n(y_true, y_pred, scalar=1000):\n",
    "    \"\"\"\n",
    "    takes two [n,1,2] tensors and returns the mean of log(distance/scalar + 1)\n",
    "    between each predicted and true position.\n",
    "    \"\"\"\n",
    "    # trying to make it work with lstm but ultimately failed because I can't use\n",
    "    # sequential model for multitarget lstm.\n",
    "    if y_true.shape[1:] != y_pred.shape[1:]:\n",
    "        raise ValueError(\"passed tensors have different shape \"\n",
    "                         + str(y_true.shape) + \" \"\n",
    "                         + str(y_pred.shape) + \"\\n\"\n",
    "                         + str(y_true) + \"\\n\"\n",
    "                         + str(y_pred)\n",
    "                        )\n",
    "        \n",
    "    # log mae calculation\n",
    "    dx2 = (y_true[:,:,0] - y_pred[:,:,0])**2\n",
    "    dy2 = (y_true[:,:,1] - y_pred[:,:,1])**2\n",
    "    dist = (dx2 + dy2)**.5\n",
    "    log_dist = tf.math.log(dist/scalar + 1)\n",
    "    log_dist_mean = tf.math.reduce_mean(log_dist)\n",
    "    return log_dist_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_distance_sqrt(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    takes two [n,1,2] tensors and returns the mean of sqrt(distance)\n",
    "    between each predicted and true position.\n",
    "    \"\"\"\n",
    "    # trying to make it work with lstm but ultimately failed because I can't use\n",
    "    # sequential model for multitarget lstm.\n",
    "    if y_true.shape[1:] != y_pred.shape[1:]:\n",
    "        raise ValueError(\"passed tensors have different shape \"\n",
    "                         + str(y_true.shape) + \" \"\n",
    "                         + str(y_pred.shape) + \"\\n\"\n",
    "                         + str(y_true) + \"\\n\"\n",
    "                         + str(y_pred)\n",
    "                        )\n",
    "        \n",
    "    # sqrt mean error calculation\n",
    "    dx2 = (y_true[:,:,0] - y_pred[:,:,0])**2\n",
    "    dy2 = (y_true[:,:,1] - y_pred[:,:,1])**2\n",
    "    root_dist = (dx2 + dy2)**.25\n",
    "    root_dist_mean = tf.math.reduce_mean(root_dist)\n",
    "    return root_dist_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([340, 1, 61])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([340, 2, 61])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([340, 3, 61])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([340, 3, 61])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([340, 3, 61])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([340, 3, 61])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([340, 3, 61])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# going to use a subset of the conv test set as my test set\n",
    "train = {}\n",
    "val = {}\n",
    "test = {}\n",
    "train[1] = single_step_window.train\n",
    "val[1] = single_step_window.val\n",
    "for i in sorted(windows.keys()):\n",
    "    train[i] = windows[i].train\n",
    "    val[i] = windows[i].val\n",
    "\n",
    "# i is largest lookback size\n",
    "# use largest window's test set as test set for other windows by slicing largest window\n",
    "test[i] = windows[i].test\n",
    "for n in range(1,i):\n",
    "    test[n] = (test[i][0][:,-n:,:], test[i][1])\n",
    "    display(test[n][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old baseline class which does very bad\n",
    "class Baseline(tf.keras.Model):\n",
    "    def __init__(self, label_index=None):\n",
    "        super().__init__()\n",
    "        self.label_index = label_index\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.label_index is None:\n",
    "            return inputs\n",
    "        elif isinstance(self.label_index,(list,tuple)):\n",
    "            return inputs[:,:, self.label_index[0]:self.label_index[1]+1]\n",
    "        result = inputs[:, :, self.label_index]\n",
    "        return result[:, :, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(label_index=[column_indices[\"playerx\"],column_indices[\"playery\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a model for each lookback\n",
    "multi_dense_models = {}\n",
    "for k in sorted(windows.keys()):\n",
    "    multi_dense_models[k] = tf.keras.Sequential([\n",
    "        # Shape: (time, features) => (time*features)\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=2),\n",
    "        # Add back the time dimension.\n",
    "        # Shape: (outputs) => (1, outputs) --- this is from guide's code\n",
    "        # looks like it might be causing plotting errs -----\n",
    "        # nvm :( i wish it was the cause\n",
    "        tf.keras.layers.Reshape([1, -1]),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a model for each lookback\n",
    "conv_models = {}\n",
    "for k in sorted(windows.keys()):\n",
    "    conv_models[k] = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv1D(filters=32,\n",
    "                               kernel_size=(k),\n",
    "                               activation='relu'),\n",
    "        tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=2),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lstm model isn't functional yet sob\n",
    "\"\"\"lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=2)\n",
    "])\"\"\"\n",
    "\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling models using custom MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossli = tensor_distance_mae #[tensor_distance_mae, tensor_distance_log_n, tensor_distance_sqrt]\n",
    "metricli = tensor_distance_mae #[tensor_distance_mae, tensor_distance_log_n, tensor_distance_sqrt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.compile(loss=lossli,\n",
    "                 metrics=metricli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.compile(loss=lossli,\n",
    "               metrics=metricli,\n",
    "               optimizer=tf.optimizers.Adam()\n",
    "              )\n",
    "dense.compile(loss=lossli,\n",
    "               metrics=metricli,\n",
    "               optimizer=tf.optimizers.Adam()\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in multi_dense_models.values():\n",
    "    model.compile(loss=lossli,\n",
    "                   metrics=metricli,\n",
    "                   optimizer=tf.optimizers.Adam()\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model in conv_models.values():\n",
    "    model.compile(loss=lossli,\n",
    "               metrics=metricli,\n",
    "               optimizer=tf.optimizers.Adam()\n",
    "              )\n",
    "# lstm model isn't functional yet sob\n",
    "\"\"\"lstm_model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "               metrics=tf.losses.MeanSquaredError(),\n",
    "               #optimizer=tf.optimizers.Adam()\n",
    "              )\"\"\"\n",
    "\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 5686.1006 - tensor_distance_mae: 5686.1006 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 2/30\n",
      "95/95 [==============================] - 0s 916us/step - loss: 5686.1001 - tensor_distance_mae: 5686.1001 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 3/30\n",
      "95/95 [==============================] - 0s 821us/step - loss: 5686.1006 - tensor_distance_mae: 5686.1006 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 4/30\n",
      "95/95 [==============================] - 0s 955us/step - loss: 5686.1006 - tensor_distance_mae: 5686.1006 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 5/30\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 5686.1001 - tensor_distance_mae: 5686.1001 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 6/30\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 5686.1006 - tensor_distance_mae: 5686.1006 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 7/30\n",
      "95/95 [==============================] - 0s 887us/step - loss: 5686.1001 - tensor_distance_mae: 5686.1001 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 8/30\n",
      "95/95 [==============================] - 0s 747us/step - loss: 5686.1006 - tensor_distance_mae: 5686.1006 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 9/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 5686.1001 - tensor_distance_mae: 5686.1001 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 10/30\n",
      "95/95 [==============================] - 0s 835us/step - loss: 5686.1011 - tensor_distance_mae: 5686.1011 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 11/30\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 5686.1001 - tensor_distance_mae: 5686.1001 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 12/30\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 5686.1006 - tensor_distance_mae: 5686.1006 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 13/30\n",
      "95/95 [==============================] - 0s 911us/step - loss: 5686.1006 - tensor_distance_mae: 5686.1006 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 14/30\n",
      "95/95 [==============================] - 0s 881us/step - loss: 5686.1025 - tensor_distance_mae: 5686.1025 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 15/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 5686.1006 - tensor_distance_mae: 5686.1006 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 16/30\n",
      "95/95 [==============================] - 0s 951us/step - loss: 5686.1006 - tensor_distance_mae: 5686.1006 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 17/30\n",
      "95/95 [==============================] - 0s 814us/step - loss: 5686.1006 - tensor_distance_mae: 5686.1006 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 18/30\n",
      "95/95 [==============================] - 0s 959us/step - loss: 5686.1006 - tensor_distance_mae: 5686.1006 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 19/30\n",
      "95/95 [==============================] - 0s 741us/step - loss: 5686.1001 - tensor_distance_mae: 5686.1001 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 20/30\n",
      "95/95 [==============================] - 0s 788us/step - loss: 5686.0991 - tensor_distance_mae: 5686.0991 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 21/30\n",
      "95/95 [==============================] - 0s 739us/step - loss: 5686.1006 - tensor_distance_mae: 5686.1006 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 22/30\n",
      "95/95 [==============================] - 0s 691us/step - loss: 5686.1001 - tensor_distance_mae: 5686.1001 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 23/30\n",
      "95/95 [==============================] - 0s 697us/step - loss: 5686.1006 - tensor_distance_mae: 5686.1006 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 24/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 5686.1011 - tensor_distance_mae: 5686.1011 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 25/30\n",
      "95/95 [==============================] - 0s 901us/step - loss: 5686.1001 - tensor_distance_mae: 5686.1001 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 26/30\n",
      "95/95 [==============================] - 0s 704us/step - loss: 5686.1006 - tensor_distance_mae: 5686.1006 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 27/30\n",
      "95/95 [==============================] - 0s 701us/step - loss: 5686.1006 - tensor_distance_mae: 5686.1006 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 28/30\n",
      "95/95 [==============================] - 0s 684us/step - loss: 5686.1006 - tensor_distance_mae: 5686.1006 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 29/30\n",
      "95/95 [==============================] - 0s 685us/step - loss: 5686.1006 - tensor_distance_mae: 5686.1006 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n",
      "Epoch 30/30\n",
      "95/95 [==============================] - 0s 785us/step - loss: 5686.0991 - tensor_distance_mae: 5686.0991 - val_loss: 5639.1006 - val_tensor_distance_mae: 5633.8325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff875f7efd0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.fit(x=train[1][0],\n",
    "           y=train[1][1],\n",
    "           batch_size=32,\n",
    "           epochs=30,\n",
    "           verbose=1,\n",
    "           validation_data=val[1]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 6174.8511 - tensor_distance_mae: 6174.8511 - val_loss: 5233.4277 - val_tensor_distance_mae: 5225.3931\n",
      "Epoch 2/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 5200.9028 - tensor_distance_mae: 5200.9028 - val_loss: 4803.9233 - val_tensor_distance_mae: 4798.1118\n",
      "Epoch 3/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 4870.7832 - tensor_distance_mae: 4870.7832 - val_loss: 4644.4077 - val_tensor_distance_mae: 4639.1357\n",
      "Epoch 4/30\n",
      "95/95 [==============================] - 0s 910us/step - loss: 4725.0015 - tensor_distance_mae: 4725.0015 - val_loss: 4557.2080 - val_tensor_distance_mae: 4551.8960\n",
      "Epoch 5/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 4617.9502 - tensor_distance_mae: 4617.9502 - val_loss: 4536.2012 - val_tensor_distance_mae: 4531.1538\n",
      "Epoch 6/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 4554.2554 - tensor_distance_mae: 4554.2554 - val_loss: 4482.3750 - val_tensor_distance_mae: 4477.0532\n",
      "Epoch 7/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 4492.0864 - tensor_distance_mae: 4492.0864 - val_loss: 4403.2188 - val_tensor_distance_mae: 4397.9111\n",
      "Epoch 8/30\n",
      "95/95 [==============================] - 0s 926us/step - loss: 4451.4478 - tensor_distance_mae: 4451.4478 - val_loss: 4418.3477 - val_tensor_distance_mae: 4413.6191\n",
      "Epoch 9/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 4419.4619 - tensor_distance_mae: 4419.4619 - val_loss: 4365.4155 - val_tensor_distance_mae: 4360.7041\n",
      "Epoch 10/30\n",
      "95/95 [==============================] - 0s 961us/step - loss: 4398.9761 - tensor_distance_mae: 4398.9761 - val_loss: 4445.9648 - val_tensor_distance_mae: 4442.4536\n",
      "Epoch 11/30\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 4373.2344 - tensor_distance_mae: 4373.2344 - val_loss: 4365.2827 - val_tensor_distance_mae: 4361.5830\n",
      "Epoch 12/30\n",
      "95/95 [==============================] - 0s 885us/step - loss: 4362.3130 - tensor_distance_mae: 4362.3130 - val_loss: 4340.0669 - val_tensor_distance_mae: 4336.1934\n",
      "Epoch 13/30\n",
      "95/95 [==============================] - 0s 847us/step - loss: 4356.4258 - tensor_distance_mae: 4356.4258 - val_loss: 4302.2676 - val_tensor_distance_mae: 4298.4751\n",
      "Epoch 14/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 4325.6548 - tensor_distance_mae: 4325.6548 - val_loss: 4289.8965 - val_tensor_distance_mae: 4286.2559\n",
      "Epoch 15/30\n",
      "95/95 [==============================] - 0s 873us/step - loss: 4309.9561 - tensor_distance_mae: 4309.9561 - val_loss: 4326.2661 - val_tensor_distance_mae: 4323.6235\n",
      "Epoch 16/30\n",
      "95/95 [==============================] - 0s 903us/step - loss: 4303.5708 - tensor_distance_mae: 4303.5708 - val_loss: 4302.5254 - val_tensor_distance_mae: 4299.9097\n",
      "Epoch 17/30\n",
      "95/95 [==============================] - 0s 891us/step - loss: 4292.1128 - tensor_distance_mae: 4292.1128 - val_loss: 4256.4536 - val_tensor_distance_mae: 4253.0049\n",
      "Epoch 18/30\n",
      "95/95 [==============================] - 0s 878us/step - loss: 4293.3271 - tensor_distance_mae: 4293.3271 - val_loss: 4255.3901 - val_tensor_distance_mae: 4252.2896\n",
      "Epoch 19/30\n",
      "95/95 [==============================] - 0s 873us/step - loss: 4281.7305 - tensor_distance_mae: 4281.7305 - val_loss: 4260.0469 - val_tensor_distance_mae: 4257.4097\n",
      "Epoch 20/30\n",
      "95/95 [==============================] - 0s 834us/step - loss: 4274.9390 - tensor_distance_mae: 4274.9390 - val_loss: 4254.5547 - val_tensor_distance_mae: 4252.1309\n",
      "Epoch 21/30\n",
      "95/95 [==============================] - 0s 812us/step - loss: 4265.9106 - tensor_distance_mae: 4265.9106 - val_loss: 4332.0757 - val_tensor_distance_mae: 4331.1016\n",
      "Epoch 22/30\n",
      "95/95 [==============================] - 0s 888us/step - loss: 4276.7227 - tensor_distance_mae: 4276.7227 - val_loss: 4304.3403 - val_tensor_distance_mae: 4302.9043\n",
      "Epoch 23/30\n",
      "95/95 [==============================] - 0s 911us/step - loss: 4272.4609 - tensor_distance_mae: 4272.4609 - val_loss: 4264.0649 - val_tensor_distance_mae: 4262.3345\n",
      "Epoch 24/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 4258.8364 - tensor_distance_mae: 4258.8364 - val_loss: 4238.2261 - val_tensor_distance_mae: 4236.2505\n",
      "Epoch 25/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 4256.3350 - tensor_distance_mae: 4256.3350 - val_loss: 4248.3916 - val_tensor_distance_mae: 4246.8247\n",
      "Epoch 26/30\n",
      "95/95 [==============================] - 0s 898us/step - loss: 4255.3110 - tensor_distance_mae: 4255.3110 - val_loss: 4243.6177 - val_tensor_distance_mae: 4242.0928\n",
      "Epoch 27/30\n",
      "95/95 [==============================] - 0s 876us/step - loss: 4248.1543 - tensor_distance_mae: 4248.1543 - val_loss: 4254.6987 - val_tensor_distance_mae: 4253.5356\n",
      "Epoch 28/30\n",
      "95/95 [==============================] - 0s 849us/step - loss: 4252.2842 - tensor_distance_mae: 4252.2842 - val_loss: 4235.1514 - val_tensor_distance_mae: 4233.7056\n",
      "Epoch 29/30\n",
      "95/95 [==============================] - 0s 859us/step - loss: 4247.4995 - tensor_distance_mae: 4247.4995 - val_loss: 4226.5874 - val_tensor_distance_mae: 4224.8984\n",
      "Epoch 30/30\n",
      "95/95 [==============================] - 0s 833us/step - loss: 4242.6772 - tensor_distance_mae: 4242.6772 - val_loss: 4251.6636 - val_tensor_distance_mae: 4250.8101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff878ec8bd0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.fit(x=train[1][0],\n",
    "           y=train[1][1],\n",
    "           batch_size=32,\n",
    "           epochs=30,\n",
    "           verbose=1,\n",
    "           validation_data=val[1]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 1/95 [..............................] - ETA: 0s - loss: 10648.0762 - tensor_distance_mae: 10648.0762WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0016s). Check your callbacks.\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 4834.3633 - tensor_distance_mae: 4834.3633 - val_loss: 4298.4917 - val_tensor_distance_mae: 4296.8413\n",
      "Epoch 2/30\n",
      "95/95 [==============================] - 0s 985us/step - loss: 4263.2568 - tensor_distance_mae: 4263.2568 - val_loss: 4243.3662 - val_tensor_distance_mae: 4241.4487\n",
      "Epoch 3/30\n",
      "95/95 [==============================] - 0s 957us/step - loss: 4213.0298 - tensor_distance_mae: 4213.0298 - val_loss: 4165.1572 - val_tensor_distance_mae: 4163.1064\n",
      "Epoch 4/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 4174.6680 - tensor_distance_mae: 4174.6680 - val_loss: 4257.6396 - val_tensor_distance_mae: 4255.8618\n",
      "Epoch 5/30\n",
      "95/95 [==============================] - 0s 965us/step - loss: 4144.6875 - tensor_distance_mae: 4144.6875 - val_loss: 4211.1011 - val_tensor_distance_mae: 4209.3711\n",
      "Epoch 6/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 4129.1235 - tensor_distance_mae: 4129.1235 - val_loss: 4142.8447 - val_tensor_distance_mae: 4140.6997\n",
      "Epoch 7/30\n",
      "95/95 [==============================] - 0s 943us/step - loss: 4107.9307 - tensor_distance_mae: 4107.9307 - val_loss: 4154.3901 - val_tensor_distance_mae: 4152.2881\n",
      "Epoch 8/30\n",
      "95/95 [==============================] - 0s 994us/step - loss: 4091.2063 - tensor_distance_mae: 4091.2063 - val_loss: 4169.3560 - val_tensor_distance_mae: 4167.2026\n",
      "Epoch 9/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 4071.3713 - tensor_distance_mae: 4071.3713 - val_loss: 4187.9663 - val_tensor_distance_mae: 4185.3745\n",
      "Epoch 10/30\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 4035.5046 - tensor_distance_mae: 4035.5046 - val_loss: 4233.9229 - val_tensor_distance_mae: 4231.9321\n",
      "Epoch 11/30\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 4047.0085 - tensor_distance_mae: 4047.0085 - val_loss: 4251.5342 - val_tensor_distance_mae: 4249.4604\n",
      "Epoch 12/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 4020.8210 - tensor_distance_mae: 4020.8210 - val_loss: 4176.0884 - val_tensor_distance_mae: 4172.5415\n",
      "Epoch 13/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 4007.9675 - tensor_distance_mae: 4007.9675 - val_loss: 4172.9170 - val_tensor_distance_mae: 4170.7402\n",
      "Epoch 14/30\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 3987.3928 - tensor_distance_mae: 3987.3928 - val_loss: 4240.0850 - val_tensor_distance_mae: 4238.0625\n",
      "Epoch 15/30\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 3960.9226 - tensor_distance_mae: 3960.9226 - val_loss: 4241.3403 - val_tensor_distance_mae: 4240.7974\n",
      "Epoch 16/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 3925.8560 - tensor_distance_mae: 3925.8560 - val_loss: 4281.7505 - val_tensor_distance_mae: 4279.3179\n",
      "Epoch 17/30\n",
      "95/95 [==============================] - 0s 964us/step - loss: 3938.0808 - tensor_distance_mae: 3938.0808 - val_loss: 4235.8955 - val_tensor_distance_mae: 4233.1431\n",
      "Epoch 18/30\n",
      "95/95 [==============================] - 0s 944us/step - loss: 3918.6582 - tensor_distance_mae: 3918.6582 - val_loss: 4270.0137 - val_tensor_distance_mae: 4270.0293\n",
      "Epoch 19/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 3893.7861 - tensor_distance_mae: 3893.7861 - val_loss: 4184.4048 - val_tensor_distance_mae: 4183.4355\n",
      "Epoch 20/30\n",
      "95/95 [==============================] - 0s 971us/step - loss: 3865.4688 - tensor_distance_mae: 3865.4688 - val_loss: 4241.8794 - val_tensor_distance_mae: 4240.9614\n",
      "Epoch 21/30\n",
      "95/95 [==============================] - 0s 953us/step - loss: 3857.7300 - tensor_distance_mae: 3857.7300 - val_loss: 4310.7998 - val_tensor_distance_mae: 4310.3921\n",
      "Epoch 22/30\n",
      "95/95 [==============================] - 0s 973us/step - loss: 3849.9897 - tensor_distance_mae: 3849.9897 - val_loss: 4229.8188 - val_tensor_distance_mae: 4229.7734\n",
      "Epoch 23/30\n",
      "95/95 [==============================] - 0s 958us/step - loss: 3819.2461 - tensor_distance_mae: 3819.2461 - val_loss: 4207.6123 - val_tensor_distance_mae: 4206.2856\n",
      "Epoch 24/30\n",
      "95/95 [==============================] - 0s 964us/step - loss: 3790.4321 - tensor_distance_mae: 3790.4321 - val_loss: 4278.9473 - val_tensor_distance_mae: 4278.5439\n",
      "Epoch 25/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 3773.4214 - tensor_distance_mae: 3773.4214 - val_loss: 4278.3442 - val_tensor_distance_mae: 4278.8726\n",
      "Epoch 26/30\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 3765.0957 - tensor_distance_mae: 3765.0957 - val_loss: 4288.9321 - val_tensor_distance_mae: 4287.1372\n",
      "Epoch 27/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 3741.9978 - tensor_distance_mae: 3741.9978 - val_loss: 4188.7080 - val_tensor_distance_mae: 4187.2700\n",
      "Epoch 28/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 3724.7017 - tensor_distance_mae: 3724.7017 - val_loss: 4237.2065 - val_tensor_distance_mae: 4237.4990\n",
      "Epoch 29/30\n",
      "95/95 [==============================] - 0s 930us/step - loss: 3708.6089 - tensor_distance_mae: 3708.6089 - val_loss: 4257.9785 - val_tensor_distance_mae: 4257.1738\n",
      "Epoch 30/30\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 3676.9780 - tensor_distance_mae: 3676.9780 - val_loss: 4282.3965 - val_tensor_distance_mae: 4282.3638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff876570710>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense.fit(x=train[1][0],\n",
    "           y=train[1][1],\n",
    "           batch_size=32,\n",
    "           epochs=30,\n",
    "           verbose=1,\n",
    "           validation_data=val[1]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 5261.2334 - tensor_distance_mae: 5261.2334 - val_loss: 4371.8691 - val_tensor_distance_mae: 4371.8691\n",
      "Epoch 2/30\n",
      "80/80 [==============================] - 0s 970us/step - loss: 4392.8027 - tensor_distance_mae: 4392.8027 - val_loss: 4244.6240 - val_tensor_distance_mae: 4244.6240\n",
      "Epoch 3/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4309.8384 - tensor_distance_mae: 4309.8384 - val_loss: 4165.2197 - val_tensor_distance_mae: 4165.2197\n",
      "Epoch 4/30\n",
      "80/80 [==============================] - 0s 959us/step - loss: 4260.9307 - tensor_distance_mae: 4260.9307 - val_loss: 4219.8545 - val_tensor_distance_mae: 4219.8545\n",
      "Epoch 5/30\n",
      "80/80 [==============================] - 0s 966us/step - loss: 4236.4214 - tensor_distance_mae: 4236.4214 - val_loss: 4149.7656 - val_tensor_distance_mae: 4149.7656\n",
      "Epoch 6/30\n",
      "80/80 [==============================] - 0s 973us/step - loss: 4216.5151 - tensor_distance_mae: 4216.5151 - val_loss: 4220.4019 - val_tensor_distance_mae: 4220.4019\n",
      "Epoch 7/30\n",
      "80/80 [==============================] - 0s 961us/step - loss: 4173.2017 - tensor_distance_mae: 4173.2017 - val_loss: 4135.1069 - val_tensor_distance_mae: 4135.1069\n",
      "Epoch 8/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4159.2969 - tensor_distance_mae: 4159.2969 - val_loss: 4137.3931 - val_tensor_distance_mae: 4137.3931\n",
      "Epoch 9/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4131.5972 - tensor_distance_mae: 4131.5972 - val_loss: 4169.0151 - val_tensor_distance_mae: 4169.0151\n",
      "Epoch 10/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4113.0537 - tensor_distance_mae: 4113.0537 - val_loss: 4159.1914 - val_tensor_distance_mae: 4159.1914\n",
      "Epoch 11/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4078.3081 - tensor_distance_mae: 4078.3081 - val_loss: 4151.2939 - val_tensor_distance_mae: 4151.2939\n",
      "Epoch 12/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4041.1165 - tensor_distance_mae: 4041.1165 - val_loss: 4113.4180 - val_tensor_distance_mae: 4113.4180\n",
      "Epoch 13/30\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4031.6504 - tensor_distance_mae: 4031.6504 - val_loss: 4126.3472 - val_tensor_distance_mae: 4126.3472\n",
      "Epoch 14/30\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4039.2603 - tensor_distance_mae: 4039.2603 - val_loss: 4142.7153 - val_tensor_distance_mae: 4142.7153\n",
      "Epoch 15/30\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4034.4771 - tensor_distance_mae: 4034.4771 - val_loss: 4132.1255 - val_tensor_distance_mae: 4132.1255\n",
      "Epoch 16/30\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 3993.9114 - tensor_distance_mae: 3993.9114 - val_loss: 4267.2881 - val_tensor_distance_mae: 4267.2881\n",
      "Epoch 17/30\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3968.1770 - tensor_distance_mae: 3968.1770 - val_loss: 4165.6025 - val_tensor_distance_mae: 4165.6025\n",
      "Epoch 18/30\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3962.3184 - tensor_distance_mae: 3962.3184 - val_loss: 4198.3623 - val_tensor_distance_mae: 4198.3623\n",
      "Epoch 19/30\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3932.8367 - tensor_distance_mae: 3932.8367 - val_loss: 4175.7856 - val_tensor_distance_mae: 4175.7856\n",
      "Epoch 20/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3914.1797 - tensor_distance_mae: 3914.1797 - val_loss: 4120.4951 - val_tensor_distance_mae: 4120.4951\n",
      "Epoch 21/30\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3894.9917 - tensor_distance_mae: 3894.9917 - val_loss: 4161.3960 - val_tensor_distance_mae: 4161.3960\n",
      "Epoch 22/30\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3861.3784 - tensor_distance_mae: 3861.3784 - val_loss: 4139.3975 - val_tensor_distance_mae: 4139.3975\n",
      "Epoch 23/30\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3847.4556 - tensor_distance_mae: 3847.4556 - val_loss: 4173.2949 - val_tensor_distance_mae: 4173.2949\n",
      "Epoch 24/30\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3853.1575 - tensor_distance_mae: 3853.1575 - val_loss: 4200.3354 - val_tensor_distance_mae: 4200.3354\n",
      "Epoch 25/30\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 3836.4875 - tensor_distance_mae: 3836.4875 - val_loss: 4225.7876 - val_tensor_distance_mae: 4225.7876\n",
      "Epoch 26/30\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 3819.6555 - tensor_distance_mae: 3819.6555 - val_loss: 4222.1514 - val_tensor_distance_mae: 4222.1514\n",
      "Epoch 27/30\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3764.9558 - tensor_distance_mae: 3764.9558 - val_loss: 4194.6763 - val_tensor_distance_mae: 4194.6763\n",
      "Epoch 28/30\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 3746.8589 - tensor_distance_mae: 3746.8589 - val_loss: 4245.0073 - val_tensor_distance_mae: 4245.0073\n",
      "Epoch 29/30\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 3749.0996 - tensor_distance_mae: 3749.0996 - val_loss: 4246.0796 - val_tensor_distance_mae: 4246.0796\n",
      "Epoch 30/30\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3726.1606 - tensor_distance_mae: 3726.1606 - val_loss: 4265.9473 - val_tensor_distance_mae: 4265.9473\n",
      "Epoch 1/30\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4671.4751 - tensor_distance_mae: 4671.4751 - val_loss: 4221.8569 - val_tensor_distance_mae: 4250.9507\n",
      "Epoch 2/30\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 4288.3242 - tensor_distance_mae: 4288.3242 - val_loss: 4153.3711 - val_tensor_distance_mae: 4189.7964\n",
      "Epoch 3/30\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 4211.9756 - tensor_distance_mae: 4211.9756 - val_loss: 4168.2056 - val_tensor_distance_mae: 4204.5103\n",
      "Epoch 4/30\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 4190.2036 - tensor_distance_mae: 4190.2036 - val_loss: 4141.5000 - val_tensor_distance_mae: 4162.5161\n",
      "Epoch 5/30\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 4171.9214 - tensor_distance_mae: 4171.9214 - val_loss: 4178.9814 - val_tensor_distance_mae: 4222.5073\n",
      "Epoch 6/30\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 4126.6523 - tensor_distance_mae: 4126.6523 - val_loss: 4125.2173 - val_tensor_distance_mae: 4165.9126\n",
      "Epoch 7/30\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 4102.8496 - tensor_distance_mae: 4102.8496 - val_loss: 4114.3994 - val_tensor_distance_mae: 4154.7710\n",
      "Epoch 8/30\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 4102.8574 - tensor_distance_mae: 4102.8574 - val_loss: 4145.1978 - val_tensor_distance_mae: 4194.9517\n",
      "Epoch 9/30\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4074.0608 - tensor_distance_mae: 4074.0608 - val_loss: 4110.7178 - val_tensor_distance_mae: 4154.6699\n",
      "Epoch 10/30\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4076.9163 - tensor_distance_mae: 4076.9163 - val_loss: 4120.5186 - val_tensor_distance_mae: 4170.7690\n",
      "Epoch 11/30\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 4044.4263 - tensor_distance_mae: 4044.4263 - val_loss: 4138.7100 - val_tensor_distance_mae: 4196.3306\n",
      "Epoch 12/30\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 4037.1919 - tensor_distance_mae: 4037.1919 - val_loss: 4150.5488 - val_tensor_distance_mae: 4183.1377\n",
      "Epoch 13/30\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 4022.9639 - tensor_distance_mae: 4022.9639 - val_loss: 4175.7661 - val_tensor_distance_mae: 4222.9058\n",
      "Epoch 14/30\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 4007.2119 - tensor_distance_mae: 4007.2119 - val_loss: 4111.6089 - val_tensor_distance_mae: 4162.0098\n",
      "Epoch 15/30\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 3986.6301 - tensor_distance_mae: 3986.6301 - val_loss: 4167.9165 - val_tensor_distance_mae: 4202.8511\n",
      "Epoch 16/30\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 3977.8052 - tensor_distance_mae: 3977.8052 - val_loss: 4290.2422 - val_tensor_distance_mae: 4368.5278\n",
      "Epoch 17/30\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 3961.2329 - tensor_distance_mae: 3961.2329 - val_loss: 4109.5791 - val_tensor_distance_mae: 4149.0698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 3969.6958 - tensor_distance_mae: 3969.6958 - val_loss: 4124.8359 - val_tensor_distance_mae: 4177.4775\n",
      "Epoch 19/30\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 3928.1958 - tensor_distance_mae: 3928.1958 - val_loss: 4115.0859 - val_tensor_distance_mae: 4164.4019\n",
      "Epoch 20/30\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 3925.6523 - tensor_distance_mae: 3925.6523 - val_loss: 4088.4714 - val_tensor_distance_mae: 4142.7241\n",
      "Epoch 21/30\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 3933.2971 - tensor_distance_mae: 3933.2971 - val_loss: 4091.7771 - val_tensor_distance_mae: 4135.7148\n",
      "Epoch 22/30\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 3894.1982 - tensor_distance_mae: 3894.1982 - val_loss: 4090.5994 - val_tensor_distance_mae: 4139.4761\n",
      "Epoch 23/30\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 3898.3767 - tensor_distance_mae: 3898.3767 - val_loss: 4158.6016 - val_tensor_distance_mae: 4203.4204\n",
      "Epoch 24/30\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 3886.5022 - tensor_distance_mae: 3886.5022 - val_loss: 4176.1611 - val_tensor_distance_mae: 4234.5605\n",
      "Epoch 25/30\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 3889.2930 - tensor_distance_mae: 3889.2930 - val_loss: 4132.3711 - val_tensor_distance_mae: 4190.1196\n",
      "Epoch 26/30\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 3856.2678 - tensor_distance_mae: 3856.2678 - val_loss: 4159.9116 - val_tensor_distance_mae: 4189.0332\n",
      "Epoch 27/30\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 3852.7583 - tensor_distance_mae: 3852.7583 - val_loss: 4089.3855 - val_tensor_distance_mae: 4132.8579\n",
      "Epoch 28/30\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 3848.9919 - tensor_distance_mae: 3848.9919 - val_loss: 4138.1460 - val_tensor_distance_mae: 4201.2563\n",
      "Epoch 29/30\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 3820.6851 - tensor_distance_mae: 3820.6851 - val_loss: 4124.6245 - val_tensor_distance_mae: 4185.5962\n",
      "Epoch 30/30\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 3808.0222 - tensor_distance_mae: 3808.0222 - val_loss: 4193.8145 - val_tensor_distance_mae: 4319.2354\n",
      "Epoch 1/30\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 5089.1353 - tensor_distance_mae: 5089.1353 - val_loss: 4280.0864 - val_tensor_distance_mae: 4282.3452\n",
      "Epoch 2/30\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4329.8433 - tensor_distance_mae: 4329.8433 - val_loss: 4249.5200 - val_tensor_distance_mae: 4248.7114\n",
      "Epoch 3/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 4277.5454 - tensor_distance_mae: 4277.5454 - val_loss: 4168.4990 - val_tensor_distance_mae: 4163.1396\n",
      "Epoch 4/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 4236.2900 - tensor_distance_mae: 4236.2900 - val_loss: 4149.0347 - val_tensor_distance_mae: 4142.8301\n",
      "Epoch 5/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 4223.5312 - tensor_distance_mae: 4223.5312 - val_loss: 4134.7583 - val_tensor_distance_mae: 4128.3457\n",
      "Epoch 6/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 4182.8750 - tensor_distance_mae: 4182.8750 - val_loss: 4160.5483 - val_tensor_distance_mae: 4153.4263\n",
      "Epoch 7/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 4182.0454 - tensor_distance_mae: 4182.0454 - val_loss: 4107.2031 - val_tensor_distance_mae: 4099.0659\n",
      "Epoch 8/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 4142.7998 - tensor_distance_mae: 4142.7998 - val_loss: 4136.2729 - val_tensor_distance_mae: 4130.4370\n",
      "Epoch 9/30\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4135.0146 - tensor_distance_mae: 4135.0146 - val_loss: 4135.9058 - val_tensor_distance_mae: 4129.6763\n",
      "Epoch 10/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 4116.5571 - tensor_distance_mae: 4116.5571 - val_loss: 4124.5762 - val_tensor_distance_mae: 4116.2026\n",
      "Epoch 11/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 4105.8755 - tensor_distance_mae: 4105.8755 - val_loss: 4135.8252 - val_tensor_distance_mae: 4127.2012\n",
      "Epoch 12/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 4114.8521 - tensor_distance_mae: 4114.8521 - val_loss: 4228.8799 - val_tensor_distance_mae: 4223.0337\n",
      "Epoch 13/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 4067.1299 - tensor_distance_mae: 4067.1299 - val_loss: 4162.8608 - val_tensor_distance_mae: 4154.0435\n",
      "Epoch 14/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 4061.8218 - tensor_distance_mae: 4061.8218 - val_loss: 4171.5464 - val_tensor_distance_mae: 4163.3828\n",
      "Epoch 15/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 4032.9492 - tensor_distance_mae: 4032.9492 - val_loss: 4110.3135 - val_tensor_distance_mae: 4098.9688\n",
      "Epoch 16/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 4050.0378 - tensor_distance_mae: 4050.0378 - val_loss: 4129.0430 - val_tensor_distance_mae: 4120.1279\n",
      "Epoch 17/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 4032.0452 - tensor_distance_mae: 4032.0452 - val_loss: 4133.6211 - val_tensor_distance_mae: 4125.8984\n",
      "Epoch 18/30\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3990.6963 - tensor_distance_mae: 3990.6963 - val_loss: 4130.6572 - val_tensor_distance_mae: 4122.7988\n",
      "Epoch 19/30\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3980.7922 - tensor_distance_mae: 3980.7922 - val_loss: 4201.6387 - val_tensor_distance_mae: 4196.2661\n",
      "Epoch 20/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 3957.3909 - tensor_distance_mae: 3957.3909 - val_loss: 4147.4268 - val_tensor_distance_mae: 4139.2578\n",
      "Epoch 21/30\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3944.3088 - tensor_distance_mae: 3944.3088 - val_loss: 4162.2026 - val_tensor_distance_mae: 4156.9956\n",
      "Epoch 22/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 3937.7183 - tensor_distance_mae: 3937.7183 - val_loss: 4092.2898 - val_tensor_distance_mae: 4083.3201\n",
      "Epoch 23/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 3942.1514 - tensor_distance_mae: 3942.1514 - val_loss: 4171.3682 - val_tensor_distance_mae: 4163.4155\n",
      "Epoch 24/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 3901.2573 - tensor_distance_mae: 3901.2573 - val_loss: 4149.0181 - val_tensor_distance_mae: 4138.5195\n",
      "Epoch 25/30\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3930.5515 - tensor_distance_mae: 3930.5515 - val_loss: 4179.5586 - val_tensor_distance_mae: 4171.9185\n",
      "Epoch 26/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 3888.9363 - tensor_distance_mae: 3888.9363 - val_loss: 4165.5342 - val_tensor_distance_mae: 4156.3071\n",
      "Epoch 27/30\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 3865.8486 - tensor_distance_mae: 3865.8486 - val_loss: 4241.8428 - val_tensor_distance_mae: 4232.6909\n",
      "Epoch 28/30\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 3838.3547 - tensor_distance_mae: 3838.3547 - val_loss: 4173.4609 - val_tensor_distance_mae: 4167.4927\n",
      "Epoch 29/30\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3828.4058 - tensor_distance_mae: 3828.4058 - val_loss: 4163.8843 - val_tensor_distance_mae: 4158.5474\n",
      "Epoch 30/30\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3833.3967 - tensor_distance_mae: 3833.3967 - val_loss: 4216.1284 - val_tensor_distance_mae: 4212.5620\n"
     ]
    }
   ],
   "source": [
    "for width in multi_dense_models.keys():\n",
    "    multi_dense_models[width].fit(x=train[width][0],\n",
    "           y=train[width][1],\n",
    "           batch_size=32,\n",
    "           epochs=30,\n",
    "           verbose=1,\n",
    "           validation_data=val[width]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4803.2334 - tensor_distance_mae: 4803.2334 - val_loss: 4244.9189 - val_tensor_distance_mae: 4244.9189\n",
      "Epoch 2/30\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4329.4126 - tensor_distance_mae: 4329.4126 - val_loss: 4202.4385 - val_tensor_distance_mae: 4202.4385\n",
      "Epoch 3/30\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4278.9102 - tensor_distance_mae: 4278.9102 - val_loss: 4107.6919 - val_tensor_distance_mae: 4107.6919\n",
      "Epoch 4/30\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4249.4326 - tensor_distance_mae: 4249.4326 - val_loss: 4173.0288 - val_tensor_distance_mae: 4173.0288\n",
      "Epoch 5/30\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4220.8037 - tensor_distance_mae: 4220.8037 - val_loss: 4073.8066 - val_tensor_distance_mae: 4073.8066\n",
      "Epoch 6/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4205.2822 - tensor_distance_mae: 4205.2822 - val_loss: 4075.4644 - val_tensor_distance_mae: 4075.4644\n",
      "Epoch 7/30\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4157.9038 - tensor_distance_mae: 4157.9038 - val_loss: 4078.8777 - val_tensor_distance_mae: 4078.8777\n",
      "Epoch 8/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4152.6401 - tensor_distance_mae: 4152.6401 - val_loss: 4156.7236 - val_tensor_distance_mae: 4156.7236\n",
      "Epoch 9/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4113.1177 - tensor_distance_mae: 4113.1177 - val_loss: 4263.8770 - val_tensor_distance_mae: 4263.8770\n",
      "Epoch 10/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4099.4111 - tensor_distance_mae: 4099.4111 - val_loss: 4101.3608 - val_tensor_distance_mae: 4101.3608\n",
      "Epoch 11/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4064.9414 - tensor_distance_mae: 4064.9414 - val_loss: 4142.8945 - val_tensor_distance_mae: 4142.8945\n",
      "Epoch 12/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4072.2883 - tensor_distance_mae: 4072.2883 - val_loss: 4161.9341 - val_tensor_distance_mae: 4161.9341\n",
      "Epoch 13/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4024.6223 - tensor_distance_mae: 4024.6223 - val_loss: 4100.6567 - val_tensor_distance_mae: 4100.6567\n",
      "Epoch 14/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4057.5737 - tensor_distance_mae: 4057.5737 - val_loss: 4165.2007 - val_tensor_distance_mae: 4165.2007\n",
      "Epoch 15/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4002.3516 - tensor_distance_mae: 4002.3516 - val_loss: 4113.4014 - val_tensor_distance_mae: 4113.4014\n",
      "Epoch 16/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3997.3242 - tensor_distance_mae: 3997.3242 - val_loss: 4105.4424 - val_tensor_distance_mae: 4105.4424\n",
      "Epoch 17/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3971.5305 - tensor_distance_mae: 3971.5305 - val_loss: 4110.9185 - val_tensor_distance_mae: 4110.9185\n",
      "Epoch 18/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3970.2976 - tensor_distance_mae: 3970.2976 - val_loss: 4131.4048 - val_tensor_distance_mae: 4131.4048\n",
      "Epoch 19/30\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 3948.1458 - tensor_distance_mae: 3948.1458 - val_loss: 4158.1201 - val_tensor_distance_mae: 4158.1201\n",
      "Epoch 20/30\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3928.5034 - tensor_distance_mae: 3928.5034 - val_loss: 4145.2017 - val_tensor_distance_mae: 4145.2017\n",
      "Epoch 21/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3924.0964 - tensor_distance_mae: 3924.0964 - val_loss: 4166.4658 - val_tensor_distance_mae: 4166.4658\n",
      "Epoch 22/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3917.5786 - tensor_distance_mae: 3917.5786 - val_loss: 4123.4062 - val_tensor_distance_mae: 4123.4062\n",
      "Epoch 23/30\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3905.8965 - tensor_distance_mae: 3905.8965 - val_loss: 4135.4658 - val_tensor_distance_mae: 4135.4658\n",
      "Epoch 24/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3893.6692 - tensor_distance_mae: 3893.6692 - val_loss: 4205.0420 - val_tensor_distance_mae: 4205.0420\n",
      "Epoch 25/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3863.3367 - tensor_distance_mae: 3863.3367 - val_loss: 4113.8960 - val_tensor_distance_mae: 4113.8960\n",
      "Epoch 26/30\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3880.8911 - tensor_distance_mae: 3880.8911 - val_loss: 4336.3511 - val_tensor_distance_mae: 4336.3511\n",
      "Epoch 27/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3850.6841 - tensor_distance_mae: 3850.6841 - val_loss: 4295.7554 - val_tensor_distance_mae: 4295.7554\n",
      "Epoch 28/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3856.6851 - tensor_distance_mae: 3856.6851 - val_loss: 4140.9717 - val_tensor_distance_mae: 4140.9717\n",
      "Epoch 29/30\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3821.7058 - tensor_distance_mae: 3821.7058 - val_loss: 4177.9688 - val_tensor_distance_mae: 4177.9688\n",
      "Epoch 30/30\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 3810.4844 - tensor_distance_mae: 3810.4844 - val_loss: 4227.5874 - val_tensor_distance_mae: 4227.5874\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:386 call\n        outputs = layer(inputs, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py:247 call\n        outputs = self._convolution_op(inputs, self.kernel)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:1017 convolution_v2\n        name=name)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:1147 convolution_internal\n        name=name)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:1888 conv1d\n        name=name)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py:979 conv2d\n        data_format=data_format, dilations=dilations, name=name)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:593 _create_op_internal\n        compute_device)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3485 _create_op_internal\n        op_def=op_def)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1975 __init__\n        control_input_ops, op_def)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Negative dimension size caused by subtracting 6 from 2 for '{{node sequential_14/conv1d_4/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](sequential_14/conv1d_4/conv1d/ExpandDims, sequential_14/conv1d_4/conv1d/ExpandDims_1)' with input shapes: [32,1,2,61], [1,6,61,32].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-d82aabd33154>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m            \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m            \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m           )\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:386 call\n        outputs = layer(inputs, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py:247 call\n        outputs = self._convolution_op(inputs, self.kernel)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:1017 convolution_v2\n        name=name)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:1147 convolution_internal\n        name=name)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:1888 conv1d\n        name=name)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py:979 conv2d\n        data_format=data_format, dilations=dilations, name=name)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:593 _create_op_internal\n        compute_device)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3485 _create_op_internal\n        op_def=op_def)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1975 __init__\n        control_input_ops, op_def)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Negative dimension size caused by subtracting 6 from 2 for '{{node sequential_14/conv1d_4/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](sequential_14/conv1d_4/conv1d/ExpandDims, sequential_14/conv1d_4/conv1d/ExpandDims_1)' with input shapes: [32,1,2,61], [1,6,61,32].\n"
     ]
    }
   ],
   "source": [
    "for width in conv_models.keys():\n",
    "    conv_models[width].fit(x=train[width][0],\n",
    "           y=train[width][1],\n",
    "           batch_size=32,\n",
    "           epochs=30,\n",
    "           verbose=1,\n",
    "           validation_data=val[width]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"lstm_model.fit(x=conv_train[0],\n",
    "           y=conv_train[1],\n",
    "           batch_size=32,\n",
    "           epochs=30,\n",
    "           verbose=1,\n",
    "           validation_data=conv_val\n",
    "          )\"\"\"\n",
    "\"sob\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predict center is 7500,7500 for each row\n",
    "center_pred = tf.fill(test[1][1].shape,7500.)\n",
    "center_error = float(metricli(center_pred, test[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "linear_error = linear.evaluate(test[1][0], test[1][1])\n",
    "baseline_error = baseline.evaluate(test[1][0], test[1][1])\n",
    "dense_error = dense.evaluate(test[1][0], test[1][1])\n",
    "md_err = {}\n",
    "conv_err = {}\n",
    "for i in conv_models.keys():\n",
    "    conv_err[i] = conv_models[i].evaluate(test[i][0], test[i][1])\n",
    "    md_err[i] = multi_dense_models[i].evaluate(test[i][0], test[i][1])\n",
    "    print(\"multistep dense model mae\",str(i), md_err[i][1])\n",
    "    print(\"convolutional model mae\",str(i), conv_err[i][1])\n",
    "print(\"baseline mae:\", baseline_error[1])\n",
    "print(\"center mae:\", center_error)\n",
    "print(\"linear mae:\", linear_error[1])\n",
    "print(\"dense mae:\", dense_error[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dense model\n",
    "wide_window.plot_map2(dense,input_width=1,plot_col=[\"playerx\",\"playery\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# lookback of 3\n",
    "wide_window.plot_map2(conv_models[2],input_width=2,plot_col=[\"playerx\",\"playery\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lookback of 4\n",
    "wide_window.plot_map2(conv_models[3],input_width=3,plot_col=[\"playerx\",\"playery\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lookback of 2\n",
    "wide_window.plot_map2(conv_models[4],input_width=4,plot_col=[\"playerx\",\"playery\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a small look at what a model is doing - I'd like to look more into this\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(conv_models[2], \"images/dense_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
