{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from riotwatcher import LolWatcher, ApiError\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from time import sleep\n",
    "\n",
    "with open('data/api-key.txt', 'r') as api:\n",
    "    API_KEY = api.read()\n",
    "lol_watcher = LolWatcher(API_KEY)\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4)\"+\n",
    "                    \" AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135\"+\n",
    "                    \" Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept-Charset\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "    \"Origin\": \"https://developer.riotgames.com\",\n",
    "    \"X-Riot-Token\": API_KEY\n",
    "}\n",
    "\n",
    "CHAMP_ID = 64\n",
    "TESTMATCH = \"4748107995\"\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "#import IPython\n",
    "#import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_dict = pickle.load(open(\"data/timeline-di.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameids = list(dfs_dict.keys())\n",
    "gameids.sort()\n",
    "train_ids = gameids[0:int(len(gameids)*.8)]\n",
    "val_ids = gameids[int(len(gameids)*.8):int(len(gameids)*.9)]\n",
    "test_ids = gameids[int(len(gameids)*.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>0currentGold</th>\n",
       "      <th>1currentGold</th>\n",
       "      <th>2currentGold</th>\n",
       "      <th>3currentGold</th>\n",
       "      <th>4currentGold</th>\n",
       "      <th>5currentGold</th>\n",
       "      <th>6currentGold</th>\n",
       "      <th>7currentGold</th>\n",
       "      <th>8currentGold</th>\n",
       "      <th>...</th>\n",
       "      <th>2y</th>\n",
       "      <th>3y</th>\n",
       "      <th>4y</th>\n",
       "      <th>5y</th>\n",
       "      <th>6y</th>\n",
       "      <th>7y</th>\n",
       "      <th>8y</th>\n",
       "      <th>9y</th>\n",
       "      <th>player_x</th>\n",
       "      <th>player_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>293.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>14511.0</td>\n",
       "      <td>14291.0</td>\n",
       "      <td>14223.0</td>\n",
       "      <td>14401.0</td>\n",
       "      <td>14579.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60032.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8318.0</td>\n",
       "      <td>2477.0</td>\n",
       "      <td>10387.0</td>\n",
       "      <td>11981.0</td>\n",
       "      <td>13198.0</td>\n",
       "      <td>9210.0</td>\n",
       "      <td>3006.0</td>\n",
       "      <td>2601.0</td>\n",
       "      <td>6219.0</td>\n",
       "      <td>8660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120042.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7543.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>13040.0</td>\n",
       "      <td>6831.0</td>\n",
       "      <td>8043.0</td>\n",
       "      <td>2385.0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>2795.0</td>\n",
       "      <td>12410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180078.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6613.0</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>13398.0</td>\n",
       "      <td>6545.0</td>\n",
       "      <td>6779.0</td>\n",
       "      <td>2093.0</td>\n",
       "      <td>3118.0</td>\n",
       "      <td>2426.0</td>\n",
       "      <td>13288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240098.0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>1281.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4568.0</td>\n",
       "      <td>3425.0</td>\n",
       "      <td>1858.0</td>\n",
       "      <td>13626.0</td>\n",
       "      <td>10304.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>3107.0</td>\n",
       "      <td>14391.0</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>13029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>300112.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>561.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6634.0</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>6430.0</td>\n",
       "      <td>13354.0</td>\n",
       "      <td>12494.0</td>\n",
       "      <td>7082.0</td>\n",
       "      <td>8335.0</td>\n",
       "      <td>7092.0</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>12949.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>360144.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>664.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4902.0</td>\n",
       "      <td>2990.0</td>\n",
       "      <td>2551.0</td>\n",
       "      <td>14162.0</td>\n",
       "      <td>3069.0</td>\n",
       "      <td>6686.0</td>\n",
       "      <td>3628.0</td>\n",
       "      <td>3524.0</td>\n",
       "      <td>1424.0</td>\n",
       "      <td>11756.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>420153.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>966.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7320.0</td>\n",
       "      <td>2977.0</td>\n",
       "      <td>2835.0</td>\n",
       "      <td>11601.0</td>\n",
       "      <td>5632.0</td>\n",
       "      <td>8050.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>5049.0</td>\n",
       "      <td>7888.0</td>\n",
       "      <td>7242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>480178.0</td>\n",
       "      <td>973.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>10175.0</td>\n",
       "      <td>9509.0</td>\n",
       "      <td>6825.0</td>\n",
       "      <td>3953.0</td>\n",
       "      <td>10348.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>11185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>540184.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>1517.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7040.0</td>\n",
       "      <td>3266.0</td>\n",
       "      <td>3211.0</td>\n",
       "      <td>10685.0</td>\n",
       "      <td>8818.0</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>4202.0</td>\n",
       "      <td>4630.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>8887.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  0currentGold  1currentGold  2currentGold  3currentGold  \\\n",
       "0        0.0         500.0         500.0         500.0         500.0   \n",
       "1    60032.0           0.0           0.0           0.0           0.0   \n",
       "2   120042.0         112.0         121.0         112.0          63.0   \n",
       "3   180078.0         395.0         465.0         455.0         388.0   \n",
       "4   240098.0         732.0         151.0          49.0         697.0   \n",
       "5   300112.0          74.0         561.0         360.0         326.0   \n",
       "6   360144.0         368.0         385.0          78.0         760.0   \n",
       "7   420153.0         738.0         592.0         675.0         966.0   \n",
       "8   480178.0         973.0         881.0         101.0         185.0   \n",
       "9   540184.0          67.0          22.0         464.0         621.0   \n",
       "\n",
       "   4currentGold  5currentGold  6currentGold  7currentGold  8currentGold  ...  \\\n",
       "0         500.0         500.0         500.0         500.0         500.0  ...   \n",
       "1           0.0           0.0           0.0           0.0           0.0  ...   \n",
       "2          23.0          63.0         121.0          84.0          63.0  ...   \n",
       "3         199.0         332.0         533.0         346.0         374.0  ...   \n",
       "4         394.0         662.0        1281.0          29.0         927.0  ...   \n",
       "5         241.0        1050.0        1480.0         668.0          48.0  ...   \n",
       "6         664.0          69.0          69.0          91.0         234.0  ...   \n",
       "7         269.0         431.0         389.0         262.0        1101.0  ...   \n",
       "8         183.0         961.0         297.0         367.0         544.0  ...   \n",
       "9         442.0        1517.0         625.0         801.0         834.0  ...   \n",
       "\n",
       "       2y      3y       4y       5y       6y       7y       8y       9y  \\\n",
       "0   293.0   471.0    649.0  14511.0  14291.0  14223.0  14401.0  14579.0   \n",
       "1  8318.0  2477.0  10387.0  11981.0  13198.0   9210.0   3006.0   2601.0   \n",
       "2  7543.0  1949.0   1744.0  13040.0   6831.0   8043.0   2385.0   1938.0   \n",
       "3  6613.0  1542.0   1452.0  13398.0   6545.0   6779.0   2093.0   3118.0   \n",
       "4  4568.0  3425.0   1858.0  13626.0  10304.0   2003.0   3107.0  14391.0   \n",
       "5  6634.0  1822.0   6430.0  13354.0  12494.0   7082.0   8335.0   7092.0   \n",
       "6  4902.0  2990.0   2551.0  14162.0   3069.0   6686.0   3628.0   3524.0   \n",
       "7  7320.0  2977.0   2835.0  11601.0   5632.0   8050.0   1223.0   5049.0   \n",
       "8  1566.0  1396.0   1725.0  10175.0   9509.0   6825.0   3953.0  10348.0   \n",
       "9  7040.0  3266.0   3211.0  10685.0   8818.0   7610.0   4202.0   4630.0   \n",
       "\n",
       "   player_x  player_y  \n",
       "0     560.0     581.0  \n",
       "1    6219.0    8660.0  \n",
       "2    2795.0   12410.0  \n",
       "3    2426.0   13288.0  \n",
       "4    2808.0   13029.0  \n",
       "5    3180.0   12949.0  \n",
       "6    1424.0   11756.0  \n",
       "7    7888.0    7242.0  \n",
       "8    1274.0   11185.0  \n",
       "9     996.0    8887.0  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_dict[train_ids[1]][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ids[0]\n",
    "test0 = dfs_dict[train_ids[0]][0:20].drop([\"timestamp\"],axis=1)\n",
    "test1 = dfs_dict[train_ids[1]][0:20].drop([\"timestamp\"],axis=1)\n",
    "column_indices = {name: i for i, name in enumerate(test0.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0currentGold</th>\n",
       "      <th>1currentGold</th>\n",
       "      <th>2currentGold</th>\n",
       "      <th>3currentGold</th>\n",
       "      <th>4currentGold</th>\n",
       "      <th>5currentGold</th>\n",
       "      <th>6currentGold</th>\n",
       "      <th>7currentGold</th>\n",
       "      <th>8currentGold</th>\n",
       "      <th>9currentGold</th>\n",
       "      <th>...</th>\n",
       "      <th>2y</th>\n",
       "      <th>3y</th>\n",
       "      <th>4y</th>\n",
       "      <th>5y</th>\n",
       "      <th>6y</th>\n",
       "      <th>7y</th>\n",
       "      <th>8y</th>\n",
       "      <th>9y</th>\n",
       "      <th>player_x</th>\n",
       "      <th>player_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>293.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>14511.0</td>\n",
       "      <td>14291.0</td>\n",
       "      <td>14223.0</td>\n",
       "      <td>14401.0</td>\n",
       "      <td>14579.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2040.0</td>\n",
       "      <td>2934.0</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>13791.0</td>\n",
       "      <td>7208.0</td>\n",
       "      <td>12340.0</td>\n",
       "      <td>6631.0</td>\n",
       "      <td>6206.0</td>\n",
       "      <td>1855.0</td>\n",
       "      <td>1338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6954.0</td>\n",
       "      <td>2664.0</td>\n",
       "      <td>3426.0</td>\n",
       "      <td>13392.0</td>\n",
       "      <td>11149.0</td>\n",
       "      <td>7424.0</td>\n",
       "      <td>5090.0</td>\n",
       "      <td>5090.0</td>\n",
       "      <td>2803.0</td>\n",
       "      <td>8078.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>188.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7104.0</td>\n",
       "      <td>2438.0</td>\n",
       "      <td>1681.0</td>\n",
       "      <td>13198.0</td>\n",
       "      <td>10425.0</td>\n",
       "      <td>7732.0</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>4115.0</td>\n",
       "      <td>10079.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103.0</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6376.0</td>\n",
       "      <td>4785.0</td>\n",
       "      <td>4803.0</td>\n",
       "      <td>13400.0</td>\n",
       "      <td>4863.0</td>\n",
       "      <td>7249.0</td>\n",
       "      <td>4933.0</td>\n",
       "      <td>4863.0</td>\n",
       "      <td>4858.0</td>\n",
       "      <td>8841.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>512.0</td>\n",
       "      <td>2162.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8381.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>6895.0</td>\n",
       "      <td>11652.0</td>\n",
       "      <td>9669.0</td>\n",
       "      <td>7860.0</td>\n",
       "      <td>2834.0</td>\n",
       "      <td>8403.0</td>\n",
       "      <td>8386.0</td>\n",
       "      <td>2265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>903.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>651.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5712.0</td>\n",
       "      <td>2517.0</td>\n",
       "      <td>2430.0</td>\n",
       "      <td>13919.0</td>\n",
       "      <td>6206.0</td>\n",
       "      <td>6538.0</td>\n",
       "      <td>3208.0</td>\n",
       "      <td>3208.0</td>\n",
       "      <td>7014.0</td>\n",
       "      <td>3194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1396.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5808.0</td>\n",
       "      <td>6561.0</td>\n",
       "      <td>7262.0</td>\n",
       "      <td>13925.0</td>\n",
       "      <td>6869.0</td>\n",
       "      <td>7360.0</td>\n",
       "      <td>5331.0</td>\n",
       "      <td>5331.0</td>\n",
       "      <td>11704.0</td>\n",
       "      <td>6544.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1769.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7019.0</td>\n",
       "      <td>1468.0</td>\n",
       "      <td>6495.0</td>\n",
       "      <td>12145.0</td>\n",
       "      <td>10690.0</td>\n",
       "      <td>13813.0</td>\n",
       "      <td>4627.0</td>\n",
       "      <td>4627.0</td>\n",
       "      <td>2773.0</td>\n",
       "      <td>5242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>62.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>888.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7013.0</td>\n",
       "      <td>2237.0</td>\n",
       "      <td>3061.0</td>\n",
       "      <td>12440.0</td>\n",
       "      <td>6494.0</td>\n",
       "      <td>7503.0</td>\n",
       "      <td>4476.0</td>\n",
       "      <td>4476.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>8962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>217.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5449.0</td>\n",
       "      <td>1799.0</td>\n",
       "      <td>3976.0</td>\n",
       "      <td>13763.0</td>\n",
       "      <td>8474.0</td>\n",
       "      <td>7408.0</td>\n",
       "      <td>4076.0</td>\n",
       "      <td>4076.0</td>\n",
       "      <td>2723.0</td>\n",
       "      <td>5185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>507.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>648.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5842.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>5617.0</td>\n",
       "      <td>14071.0</td>\n",
       "      <td>6041.0</td>\n",
       "      <td>7968.0</td>\n",
       "      <td>3823.0</td>\n",
       "      <td>3823.0</td>\n",
       "      <td>7079.0</td>\n",
       "      <td>5272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>141.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>940.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10023.0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>7862.0</td>\n",
       "      <td>13212.0</td>\n",
       "      <td>9892.0</td>\n",
       "      <td>8993.0</td>\n",
       "      <td>7159.0</td>\n",
       "      <td>7159.0</td>\n",
       "      <td>9581.0</td>\n",
       "      <td>9196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>666.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>1235.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>973.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3209.0</td>\n",
       "      <td>2722.0</td>\n",
       "      <td>3170.0</td>\n",
       "      <td>2066.0</td>\n",
       "      <td>3812.0</td>\n",
       "      <td>2719.0</td>\n",
       "      <td>4075.0</td>\n",
       "      <td>4195.0</td>\n",
       "      <td>13304.0</td>\n",
       "      <td>3457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1369.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>2598.0</td>\n",
       "      <td>6200.0</td>\n",
       "      <td>4558.0</td>\n",
       "      <td>10394.0</td>\n",
       "      <td>7794.0</td>\n",
       "      <td>5274.0</td>\n",
       "      <td>5274.0</td>\n",
       "      <td>8711.0</td>\n",
       "      <td>6712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>414.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>1441.0</td>\n",
       "      <td>717.0</td>\n",
       "      <td>1728.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>1264.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6243.0</td>\n",
       "      <td>4313.0</td>\n",
       "      <td>7463.0</td>\n",
       "      <td>2629.0</td>\n",
       "      <td>7430.0</td>\n",
       "      <td>7895.0</td>\n",
       "      <td>11467.0</td>\n",
       "      <td>11467.0</td>\n",
       "      <td>7998.0</td>\n",
       "      <td>6582.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>853.0</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1375.0</td>\n",
       "      <td>7568.0</td>\n",
       "      <td>9418.0</td>\n",
       "      <td>4233.0</td>\n",
       "      <td>10026.0</td>\n",
       "      <td>13848.0</td>\n",
       "      <td>7981.0</td>\n",
       "      <td>8182.0</td>\n",
       "      <td>4652.0</td>\n",
       "      <td>10214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1025.0</td>\n",
       "      <td>2141.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>1317.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>1303.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5106.0</td>\n",
       "      <td>5342.0</td>\n",
       "      <td>4593.0</td>\n",
       "      <td>5242.0</td>\n",
       "      <td>8299.0</td>\n",
       "      <td>5672.0</td>\n",
       "      <td>12479.0</td>\n",
       "      <td>8299.0</td>\n",
       "      <td>10570.0</td>\n",
       "      <td>7775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>174.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>2032.0</td>\n",
       "      <td>1186.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10290.0</td>\n",
       "      <td>6440.0</td>\n",
       "      <td>3511.0</td>\n",
       "      <td>13256.0</td>\n",
       "      <td>6492.0</td>\n",
       "      <td>7258.0</td>\n",
       "      <td>8544.0</td>\n",
       "      <td>6492.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>409.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>1622.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>9884.0</td>\n",
       "      <td>12259.0</td>\n",
       "      <td>13585.0</td>\n",
       "      <td>14033.0</td>\n",
       "      <td>11807.0</td>\n",
       "      <td>14287.0</td>\n",
       "      <td>11807.0</td>\n",
       "      <td>9594.0</td>\n",
       "      <td>10018.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0currentGold  1currentGold  2currentGold  3currentGold  4currentGold  \\\n",
       "0          500.0         500.0         500.0         500.0         500.0   \n",
       "1            0.0           0.0           0.0           0.0           0.0   \n",
       "2           84.0         121.0          63.0          21.0          23.0   \n",
       "3          188.0         753.0         346.0          80.0         243.0   \n",
       "4          103.0        1238.0         711.0         501.0         440.0   \n",
       "5          512.0        2162.0         137.0         139.0         168.0   \n",
       "6          903.0          40.0         184.0         557.0         539.0   \n",
       "7         1396.0         481.0         537.0         873.0         695.0   \n",
       "8         1769.0          29.0          41.0         715.0         119.0   \n",
       "9           62.0         669.0         384.0        1133.0         388.0   \n",
       "10         217.0         306.0         262.0         556.0         623.0   \n",
       "11         507.0         654.0         648.0          96.0         933.0   \n",
       "12         141.0         392.0         160.0         424.0        1852.0   \n",
       "13         666.0         680.0         376.0        1235.0         770.0   \n",
       "14        1369.0          89.0         781.0         333.0         388.0   \n",
       "15         414.0        1036.0        1441.0         717.0        1728.0   \n",
       "16         853.0        1498.0          90.0         947.0         406.0   \n",
       "17        1025.0        2141.0         290.0        1317.0         606.0   \n",
       "18         174.0         314.0         636.0        2032.0        1186.0   \n",
       "19         409.0         627.0        1211.0        1140.0        1622.0   \n",
       "\n",
       "    5currentGold  6currentGold  7currentGold  8currentGold  9currentGold  ...  \\\n",
       "0          500.0         500.0         500.0         500.0         500.0  ...   \n",
       "1            0.0           0.0           0.0           0.0          25.0  ...   \n",
       "2           84.0         121.0          91.0          21.0          48.0  ...   \n",
       "3          596.0         478.0         448.0         107.0         102.0  ...   \n",
       "4          112.0         432.0         669.0         514.0         331.0  ...   \n",
       "5          416.0         390.0          73.0         123.0          30.0  ...   \n",
       "6          651.0         646.0         346.0         468.0         193.0  ...   \n",
       "7         1037.0         273.0         608.0         835.0         393.0  ...   \n",
       "8         1257.0         196.0         267.0          82.0          63.0  ...   \n",
       "9          136.0         288.0         888.0         371.0         218.0  ...   \n",
       "10         204.0         601.0         128.0         788.0         466.0  ...   \n",
       "11         607.0         109.0         391.0        1480.0         827.0  ...   \n",
       "12         940.0         559.0         455.0         107.0         143.0  ...   \n",
       "13         325.0         973.0         958.0         484.0         553.0  ...   \n",
       "14        1026.0         395.0         297.0         607.0         323.0  ...   \n",
       "15          78.0         738.0        1264.0         131.0          59.0  ...   \n",
       "16         496.0        1080.0          53.0         470.0         328.0  ...   \n",
       "17         805.0        1303.0         307.0         928.0         550.0  ...   \n",
       "18          87.0         226.0         568.0         630.0         105.0  ...   \n",
       "19         628.0          78.0          81.0         147.0         275.0  ...   \n",
       "\n",
       "         2y      3y       4y       5y       6y       7y       8y       9y  \\\n",
       "0     293.0   471.0    649.0  14511.0  14291.0  14223.0  14401.0  14579.0   \n",
       "1    2040.0  2934.0   1585.0  13791.0   7208.0  12340.0   6631.0   6206.0   \n",
       "2    6954.0  2664.0   3426.0  13392.0  11149.0   7424.0   5090.0   5090.0   \n",
       "3    7104.0  2438.0   1681.0  13198.0  10425.0   7732.0   3593.0   3386.0   \n",
       "4    6376.0  4785.0   4803.0  13400.0   4863.0   7249.0   4933.0   4863.0   \n",
       "5    8381.0  1700.0   6895.0  11652.0   9669.0   7860.0   2834.0   8403.0   \n",
       "6    5712.0  2517.0   2430.0  13919.0   6206.0   6538.0   3208.0   3208.0   \n",
       "7    5808.0  6561.0   7262.0  13925.0   6869.0   7360.0   5331.0   5331.0   \n",
       "8    7019.0  1468.0   6495.0  12145.0  10690.0  13813.0   4627.0   4627.0   \n",
       "9    7013.0  2237.0   3061.0  12440.0   6494.0   7503.0   4476.0   4476.0   \n",
       "10   5449.0  1799.0   3976.0  13763.0   8474.0   7408.0   4076.0   4076.0   \n",
       "11   5842.0  3254.0   5617.0  14071.0   6041.0   7968.0   3823.0   3823.0   \n",
       "12  10023.0  2630.0   7862.0  13212.0   9892.0   8993.0   7159.0   7159.0   \n",
       "13   3209.0  2722.0   3170.0   2066.0   3812.0   2719.0   4075.0   4195.0   \n",
       "14   6037.0  2598.0   6200.0   4558.0  10394.0   7794.0   5274.0   5274.0   \n",
       "15   6243.0  4313.0   7463.0   2629.0   7430.0   7895.0  11467.0  11467.0   \n",
       "16   1375.0  7568.0   9418.0   4233.0  10026.0  13848.0   7981.0   8182.0   \n",
       "17   5106.0  5342.0   4593.0   5242.0   8299.0   5672.0  12479.0   8299.0   \n",
       "18  10290.0  6440.0   3511.0  13256.0   6492.0   7258.0   8544.0   6492.0   \n",
       "19   1227.0  9884.0  12259.0  13585.0  14033.0  11807.0  14287.0  11807.0   \n",
       "\n",
       "    player_x  player_y  \n",
       "0      560.0     361.0  \n",
       "1     1855.0    1338.0  \n",
       "2     2803.0    8078.0  \n",
       "3     4115.0   10079.0  \n",
       "4     4858.0    8841.0  \n",
       "5     8386.0    2265.0  \n",
       "6     7014.0    3194.0  \n",
       "7    11704.0    6544.0  \n",
       "8     2773.0    5242.0  \n",
       "9     3016.0    8962.0  \n",
       "10    2723.0    5185.0  \n",
       "11    7079.0    5272.0  \n",
       "12    9581.0    9196.0  \n",
       "13   13304.0    3457.0  \n",
       "14    8711.0    6712.0  \n",
       "15    7998.0    6582.0  \n",
       "16    4652.0   10214.0  \n",
       "17   10570.0    7775.0  \n",
       "18     394.0     461.0  \n",
       "19    9594.0   10018.0  \n",
       "\n",
       "[20 rows x 60 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "                 full_df=test0, val_df = test1,\n",
    "                 dfdi=dfs_dict,\n",
    "                 #train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "                 label_columns=None):\n",
    "        # Store the raw data.\n",
    "        #self.train_df = train_df\n",
    "        #self.val_df = val_df\n",
    "        #self.test_df = test_df\n",
    "        self.full_df = full_df\n",
    "        self.val_df = val_df\n",
    "        self.dfdi = dfdi\n",
    "        self.trainli = None\n",
    "        self.valli = None\n",
    "        self.testli = None\n",
    "\n",
    "        # Work out the label column indices.\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in\n",
    "                                                                        enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in\n",
    "                                                     enumerate(full_df.columns)}\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "                f'Total window size: {self.total_window_size}',\n",
    "                f'Input indices: {self.input_indices}',\n",
    "                f'Label indices: {self.label_indices}',\n",
    "                f'Label column name(s): {self.label_columns}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_window(self, features):\n",
    "    inputs = features[:, self.input_slice, :]\n",
    "    labels = features[:, self.labels_slice, :]\n",
    "    if self.label_columns is not None:\n",
    "        labels = tf.stack(\n",
    "                [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1)\n",
    "    \n",
    "\n",
    "    # Slicing doesn't preserve static shape information, so set the shapes\n",
    "    # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "    inputs.set_shape([None, self.input_width, None])\n",
    "    labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "WindowGenerator.split_window = split_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(self, model=None, plot_col=\"player_x\", max_subplots=3):\n",
    "    inputs, labels = self.example\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_col_index = self.column_indices[plot_col]\n",
    "    print(plot_col_index, type(plot_col_index))\n",
    "    max_n = min(max_subplots, len(inputs))\n",
    "    for n in range(max_n):\n",
    "        plt.subplot(3, 1, n+1)\n",
    "        plt.ylabel(f'{plot_col} [normed]')\n",
    "        plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                         label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "        if self.label_columns:\n",
    "            print(type(self.label_columns_indices))\n",
    "            label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            print(label_col_index)\n",
    "        else:\n",
    "            label_col_index = plot_col_index\n",
    "\n",
    "        if label_col_index is None:\n",
    "            continue\n",
    "\n",
    "        print(self.label_indices)\n",
    "        plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "        if model is not None:\n",
    "            predictions = model(inputs)\n",
    "            plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                                    marker='X', edgecolors='k', label='Predictions',\n",
    "                                    c='#ff7f0e', s=64)\n",
    "\n",
    "        if n == 0:\n",
    "            plt.legend()\n",
    "\n",
    "    plt.xlabel('Time [h]')\n",
    "\n",
    "WindowGenerator.plot = plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(self, data, list_me=False):\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=True,\n",
    "            batch_size=32,)\n",
    "\n",
    "    ds = ds.map(self.split_window)\n",
    "    if list_me:\n",
    "        return list(ds)\n",
    "    return ds\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_split_from_dfdi(self,splits=(.8,.9),minmax=(0,20)):\n",
    "    # minmax is start and end time of window being sampled from.\n",
    "    # splits is where the data is being split for train val test split\n",
    "    if self.dfdi is None:\n",
    "        print(\"no dfdi attached\")\n",
    "        raise KeyError(\"no dfdi attached\")\n",
    "    gameids = list(self.dfdi.keys())\n",
    "    gameids.sort()\n",
    "    train_ids = gameids[0:int(len(gameids)*splits[0])]\n",
    "    val_ids = gameids[int(len(gameids)*splits[0]):int(len(gameids)*splits[1])]\n",
    "    test_ids = gameids[int(len(gameids)*splits[1]):]\n",
    "    if self.trainli is None:\n",
    "        trainli = build_batch(self, self.dfdi, train_ids, minmax)\n",
    "        train_feats = tf.concat([batch[0] for batch in trainli], axis=0)\n",
    "        train_labels = tf.concat([batch[1] for batch in trainli], axis=0)\n",
    "        \n",
    "    if self.valli is None:\n",
    "        valli = build_batch(self, self.dfdi, val_ids, minmax)\n",
    "        val_feats = tf.concat([batch[0] for batch in valli], axis=0)\n",
    "        val_labels = tf.concat([batch[1] for batch in valli], axis=0)\n",
    "            \n",
    "    if self.testli is None:\n",
    "        testli = build_batch(self, self.dfdi, test_ids, minmax)\n",
    "        test_feats = tf.concat([batch[0] for batch in testli], axis=0)\n",
    "        test_labels = tf.concat([batch[1] for batch in testli], axis=0)\n",
    "            \n",
    "        \n",
    "    print(train_feats.shape, train_labels.shape)\n",
    "    self.train = (train_feats, train_labels)\n",
    "    self.val = (val_feats, val_labels)\n",
    "    self.test = (test_feats, test_labels)\n",
    "\n",
    "WindowGenerator.make_split_from_dfdi = make_split_from_dfdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@property\n",
    "def example(self):\n",
    "    \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "    result = getattr(self, '_example', None)\n",
    "    if result is None:\n",
    "        # No example batch was found, so get one from the `.train` dataset\n",
    "        result = next(iter(self.train))\n",
    "        # And cache it for next time\n",
    "        self._example = result\n",
    "    return result\n",
    "\n",
    "WindowGenerator.example = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_batch(self, dfdi, id_li, minmax):\n",
    "    dataset_li = []\n",
    "    for match_id in id_li:\n",
    "        df = dfdi[match_id]\n",
    "        df = df.drop([\"timestamp\"], axis=1)\n",
    "        df = df.iloc[minmax[0]:minmax[1]]\n",
    "        dataset_li = dataset_li + make_dataset(self, data=df, list_me=True)\n",
    "    return dataset_li\n",
    "\n",
    "WindowGenerator.build_batch = build_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0currentGold', '1currentGold', '2currentGold', '3currentGold',\n",
       "       '4currentGold', '5currentGold', '6currentGold', '7currentGold',\n",
       "       '8currentGold', '9currentGold', '0totalGold', '1totalGold',\n",
       "       '2totalGold', '3totalGold', '4totalGold', '5totalGold', '6totalGold',\n",
       "       '7totalGold', '8totalGold', '9totalGold', '0level', '1level', '2level',\n",
       "       '3level', '4level', '5level', '6level', '7level', '8level', '9level',\n",
       "       '0jungleMinionsKilled', '1jungleMinionsKilled', '2jungleMinionsKilled',\n",
       "       '3jungleMinionsKilled', '4jungleMinionsKilled', '5jungleMinionsKilled',\n",
       "       '6jungleMinionsKilled', '7jungleMinionsKilled', '8jungleMinionsKilled',\n",
       "       '9jungleMinionsKilled', '0x', '2x', '3x', '4x', '5x', '6x', '7x', '8x',\n",
       "       '9x', '0y', '2y', '3y', '4y', '5y', '6y', '7y', '8y', '9y', 'player_x',\n",
       "       'player_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 7\n",
       "Input indices: [0 1 2 3 4]\n",
       "Label indices: [5 6]\n",
       "Label column name(s): ['player_x', 'player_y']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2 = WindowGenerator(input_width=5, label_width=2, shift=2,\n",
    "                     label_columns=[\"player_x\",\"player_y\"])\n",
    "w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(tf.keras.Model):\n",
    "    def __init__(self, label_index=None):\n",
    "        super().__init__()\n",
    "        self.label_index = label_index\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.label_index is None:\n",
    "            return inputs\n",
    "        result = inputs[:, :, self.label_index]\n",
    "        return result[:, :, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 2\n",
       "Input indices: [0]\n",
       "Label indices: [1]\n",
       "Label column name(s): ['player_x']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_step_window = WindowGenerator(\n",
    "    input_width=1, label_width=1, shift=1,\n",
    "    label_columns=[\"player_x\"])#,\"player_y\"\n",
    "single_step_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1824, 1, 60) (1824, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "single_step_window.make_split_from_dfdi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hold = single_step_window.train# = tf.data.Dataset.from_tensor_slices([train_feats, train_labels])\n",
    "val_hold = single_step_window.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = tf.data.Dataset.from_tensor_slices(train_hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline()\n",
    "baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                 metrics=[tf.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 55685020.0000 - mean_absolute_error: 6384.0645 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 2/30\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 55685020.0000 - mean_absolute_error: 6384.0645 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 3/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 55685016.0000 - mean_absolute_error: 6384.0659 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 4/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 55685008.0000 - mean_absolute_error: 6384.0635 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 5/30\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 55685016.0000 - mean_absolute_error: 6384.0654 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 6/30\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 55685020.0000 - mean_absolute_error: 6384.0645 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 7/30\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 55685024.0000 - mean_absolute_error: 6384.0645 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 8/30\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 55685024.0000 - mean_absolute_error: 6384.0659 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 9/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 55685020.0000 - mean_absolute_error: 6384.0640 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 10/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 55685008.0000 - mean_absolute_error: 6384.0645 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 11/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 55685020.0000 - mean_absolute_error: 6384.0645 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 12/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 55685012.0000 - mean_absolute_error: 6384.0645 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 13/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 55685020.0000 - mean_absolute_error: 6384.0654 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 14/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 55685012.0000 - mean_absolute_error: 6384.0640 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 15/30\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 55685032.0000 - mean_absolute_error: 6384.0640 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 16/30\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 55685020.0000 - mean_absolute_error: 6384.0645 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 17/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 55685024.0000 - mean_absolute_error: 6384.0635 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 18/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 55685016.0000 - mean_absolute_error: 6384.0640 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 19/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 55685016.0000 - mean_absolute_error: 6384.0645 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 20/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 55685024.0000 - mean_absolute_error: 6384.0654 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 21/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 55685008.0000 - mean_absolute_error: 6384.0654 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 22/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 55685016.0000 - mean_absolute_error: 6384.0635 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 23/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 55685020.0000 - mean_absolute_error: 6384.0659 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 24/30\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 55685008.0000 - mean_absolute_error: 6384.0654 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 25/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 55685016.0000 - mean_absolute_error: 6384.0640 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 26/30\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 55685008.0000 - mean_absolute_error: 6384.0659 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 27/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 55685024.0000 - mean_absolute_error: 6384.0645 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 28/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 55685016.0000 - mean_absolute_error: 6384.0645 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 29/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 55685016.0000 - mean_absolute_error: 6384.0659 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n",
      "Epoch 30/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 55685016.0000 - mean_absolute_error: 6384.0645 - val_loss: 55685016.0000 - val_mean_absolute_error: 6384.0654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fade5e721d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.fit(x=train_hold[0],\n",
    "           y=train_hold[1],\n",
    "           batch_size=32,\n",
    "           epochs=30,\n",
    "           verbose=1,\n",
    "           validation_data=val_hold\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 24856382.0000 - mean_absolute_error: 4030.5798 - val_loss: 20724558.0000 - val_mean_absolute_error: 3681.1848\n",
      "Epoch 2/30\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 19394070.0000 - mean_absolute_error: 3586.0774 - val_loss: 18000588.0000 - val_mean_absolute_error: 3467.2251\n",
      "Epoch 3/30\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 16999886.0000 - mean_absolute_error: 3377.3975 - val_loss: 16022699.0000 - val_mean_absolute_error: 3291.3506\n",
      "Epoch 4/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 15306362.0000 - mean_absolute_error: 3222.2551 - val_loss: 14666114.0000 - val_mean_absolute_error: 3146.6174\n",
      "Epoch 5/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 14163464.0000 - mean_absolute_error: 3091.4434 - val_loss: 13620480.0000 - val_mean_absolute_error: 3029.8252\n",
      "Epoch 6/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 13257179.0000 - mean_absolute_error: 2984.8032 - val_loss: 12838613.0000 - val_mean_absolute_error: 2935.9663\n",
      "Epoch 7/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 12590033.0000 - mean_absolute_error: 2905.4932 - val_loss: 12260077.0000 - val_mean_absolute_error: 2860.5186\n",
      "Epoch 8/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 12058177.0000 - mean_absolute_error: 2834.9595 - val_loss: 11794844.0000 - val_mean_absolute_error: 2796.0198\n",
      "Epoch 9/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 11607787.0000 - mean_absolute_error: 2775.9985 - val_loss: 11466314.0000 - val_mean_absolute_error: 2757.3105\n",
      "Epoch 10/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 11408908.0000 - mean_absolute_error: 2736.1370 - val_loss: 11115516.0000 - val_mean_absolute_error: 2697.4165\n",
      "Epoch 11/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 11034165.0000 - mean_absolute_error: 2690.5820 - val_loss: 10983470.0000 - val_mean_absolute_error: 2667.5823\n",
      "Epoch 12/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 10820079.0000 - mean_absolute_error: 2654.9995 - val_loss: 10632898.0000 - val_mean_absolute_error: 2628.4536\n",
      "Epoch 13/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 10593974.0000 - mean_absolute_error: 2622.8032 - val_loss: 10543455.0000 - val_mean_absolute_error: 2617.0767\n",
      "Epoch 14/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 10463020.0000 - mean_absolute_error: 2602.3811 - val_loss: 10369143.0000 - val_mean_absolute_error: 2586.7964\n",
      "Epoch 15/30\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 10295433.0000 - mean_absolute_error: 2568.7192 - val_loss: 10222396.0000 - val_mean_absolute_error: 2557.1553\n",
      "Epoch 16/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 10189019.0000 - mean_absolute_error: 2553.0193 - val_loss: 10114151.0000 - val_mean_absolute_error: 2542.5090\n",
      "Epoch 17/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 10136797.0000 - mean_absolute_error: 2541.5518 - val_loss: 10027078.0000 - val_mean_absolute_error: 2525.8838\n",
      "Epoch 18/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 10060830.0000 - mean_absolute_error: 2526.5801 - val_loss: 9962461.0000 - val_mean_absolute_error: 2513.0825\n",
      "Epoch 19/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 9970847.0000 - mean_absolute_error: 2513.6123 - val_loss: 9925465.0000 - val_mean_absolute_error: 2502.9680\n",
      "Epoch 20/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9902015.0000 - mean_absolute_error: 2501.6274 - val_loss: 9850389.0000 - val_mean_absolute_error: 2492.2812\n",
      "Epoch 21/30\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 9859307.0000 - mean_absolute_error: 2495.2002 - val_loss: 9800932.0000 - val_mean_absolute_error: 2485.1531\n",
      "Epoch 22/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9807222.0000 - mean_absolute_error: 2483.1301 - val_loss: 9887870.0000 - val_mean_absolute_error: 2487.7085\n",
      "Epoch 23/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9786355.0000 - mean_absolute_error: 2479.2754 - val_loss: 9728547.0000 - val_mean_absolute_error: 2470.2634\n",
      "Epoch 24/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9757576.0000 - mean_absolute_error: 2472.8755 - val_loss: 9717268.0000 - val_mean_absolute_error: 2468.8433\n",
      "Epoch 25/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9728951.0000 - mean_absolute_error: 2469.8032 - val_loss: 9676504.0000 - val_mean_absolute_error: 2461.4194\n",
      "Epoch 26/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9735771.0000 - mean_absolute_error: 2464.9792 - val_loss: 9647872.0000 - val_mean_absolute_error: 2455.7097\n",
      "Epoch 27/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9714646.0000 - mean_absolute_error: 2459.1143 - val_loss: 9627508.0000 - val_mean_absolute_error: 2451.1479\n",
      "Epoch 28/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 9659042.0000 - mean_absolute_error: 2454.5791 - val_loss: 9610231.0000 - val_mean_absolute_error: 2447.7283\n",
      "Epoch 29/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 9673811.0000 - mean_absolute_error: 2459.2307 - val_loss: 9589785.0000 - val_mean_absolute_error: 2444.2798\n",
      "Epoch 30/30\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 9652404.0000 - mean_absolute_error: 2450.2830 - val_loss: 9604030.0000 - val_mean_absolute_error: 2446.6807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fade5e49990>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.fit(x=train_hold[0],\n",
    "           y=train_hold[1],\n",
    "           batch_size=32,\n",
    "           epochs=30,\n",
    "           verbose=1,\n",
    "           validation_data=val_hold\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hold = single_step_window.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_test_pred = linear.predict(x=test_hold[0])\n",
    "baseline_test_pred = baseline.predict(x=test_hold[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 11621402.0000 - mean_absolute_error: 2793.6089\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 60570472.0000 - mean_absolute_error: 6523.5928\n",
      "baseline mae error: 6523.5927734375\n",
      "linear mae error: 2793.60888671875\n"
     ]
    }
   ],
   "source": [
    "linear_error = linear.evaluate(test_hold[0], test_hold[1])#, batch_size=128)\n",
    "baseline_error = baseline.evaluate(test_hold[0], test_hold[1])\n",
    "print(\"baseline mae error:\", baseline_error[1])\n",
    "print(\"linear mae error:\", linear_error[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 11\n",
       "Input indices: [0 1 2 3 4 5 6 7 8 9]\n",
       "Label indices: [ 1  2  3  4  5  6  7  8  9 10]\n",
       "Label column name(s): ['player_x']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wide_window = WindowGenerator(\n",
    "    input_width=10, label_width=10, shift=1,\n",
    "    label_columns=[\"player_x\"])\n",
    "\n",
    "wide_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
